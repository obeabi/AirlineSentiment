{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Airline_NN_Glove.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNnB43EHRN1HkRlUOfGSgJk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/obeabi/AirlineSentiment/blob/main/Airline_NN_Glove.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJMaZXt8yoE-"
      },
      "source": [
        "# Airline Sentiment Dataset\r\n",
        "## Written by Abiola Obembe\r\n",
        "### Date: 2020-12-24\r\n",
        "\r\n",
        "### Goal: Train a classifiier to predict customer sentiment from customer review text (using NN and pretrained word embeddings i.e. glove)\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqeNHhjp25v_"
      },
      "source": [
        "A sentiment analysis job about the problems of each major U.S. airline. Twitter data was scraped from February of 2015 and contributors were asked to first classify positive, negative, and neutral tweets, followed by categorizing negative reasons (such as \"late flight\" or \"rude service\")."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LiwXn9d50qi6"
      },
      "source": [
        "## Step 1: Data Cleaning and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCi0HP5szMY8",
        "outputId": "7a55a8d1-3357-4443-99c3-3a156a52abb6"
      },
      "source": [
        "# install libraries\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "%matplotlib inline\r\n",
        "plt.rcParams['figure.figsize'] = (18.0, 12.0) # set default size of plots\r\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\r\n",
        "plt.rcParams['image.cmap'] = 'gray'\r\n",
        "\r\n",
        "\r\n",
        "print(\"installation complete!\")\r\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "installation complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "Ru8XNKar0pGE",
        "outputId": "5abebd42-d70f-4f2f-c64a-c0acf0ab5374"
      },
      "source": [
        "# Import dataset\r\n",
        "dataset = pd.read_csv('Tweets.csv', encoding= 'latin1', engine='python', quoting = 1)\r\n",
        "\r\n",
        "dataset.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>airline_sentiment_confidence</th>\n",
              "      <th>negativereason</th>\n",
              "      <th>negativereason_confidence</th>\n",
              "      <th>airline</th>\n",
              "      <th>airline_sentiment_gold</th>\n",
              "      <th>name</th>\n",
              "      <th>negativereason_gold</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>text</th>\n",
              "      <th>tweet_coord</th>\n",
              "      <th>tweet_created</th>\n",
              "      <th>tweet_location</th>\n",
              "      <th>user_timezone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>570306133677760513</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>cairdin</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:35:52 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Eastern Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>570301130888122368</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.3486</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:59 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>570301083672813571</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.6837</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>yvonnalynn</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:48 -0800</td>\n",
              "      <td>Lets Play</td>\n",
              "      <td>Central Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>570301031407624196</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Bad Flight</td>\n",
              "      <td>0.7033</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:36 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>570300817074462722</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Can't Tell</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:14:45 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             tweet_id  ...               user_timezone\n",
              "0  570306133677760513  ...  Eastern Time (US & Canada)\n",
              "1  570301130888122368  ...  Pacific Time (US & Canada)\n",
              "2  570301083672813571  ...  Central Time (US & Canada)\n",
              "3  570301031407624196  ...  Pacific Time (US & Canada)\n",
              "4  570300817074462722  ...  Pacific Time (US & Canada)\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "ZXcBWVgA2_co",
        "outputId": "abb6e4a8-ad90-4505-cdd1-2c8fcce3326e"
      },
      "source": [
        "# Drop columns not required\r\n",
        "dataset.drop(columns = ['tweet_id', 'airline_sentiment_confidence', 'negativereason', 'negativereason_confidence',\r\n",
        "                        'airline', 'airline_sentiment_gold','name','negativereason_gold','retweet_count','tweet_coord',\r\n",
        "                        'tweet_created','tweet_location','user_timezone'], axis = 1, inplace = True)\r\n",
        "dataset.head(10)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neutral</td>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>positive</td>\n",
              "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neutral</td>\n",
              "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>negative</td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>negative</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>negative</td>\n",
              "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>positive</td>\n",
              "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>neutral</td>\n",
              "      <td>@VirginAmerica Really missed a prime opportuni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>positive</td>\n",
              "      <td>@virginamerica Well, I didn'tâ¦but NOW I DO! :-D</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>positive</td>\n",
              "      <td>@VirginAmerica it was amazing, and arrived an ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  airline_sentiment                                               text\n",
              "0           neutral                @VirginAmerica What @dhepburn said.\n",
              "1          positive  @VirginAmerica plus you've added commercials t...\n",
              "2           neutral  @VirginAmerica I didn't today... Must mean I n...\n",
              "3          negative  @VirginAmerica it's really aggressive to blast...\n",
              "4          negative  @VirginAmerica and it's a really big bad thing...\n",
              "5          negative  @VirginAmerica seriously would pay $30 a fligh...\n",
              "6          positive  @VirginAmerica yes, nearly every time I fly VX...\n",
              "7           neutral  @VirginAmerica Really missed a prime opportuni...\n",
              "8          positive  @virginamerica Well, I didn'tâ¦but NOW I DO! :-D\n",
              "9          positive  @VirginAmerica it was amazing, and arrived an ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghh1CI-p4MSM",
        "outputId": "4eab8a1a-5586-4d00-8ef2-172d5ad48582"
      },
      "source": [
        "#  Investigate the number of distinct sentiments\r\n",
        "dataset['airline_sentiment'].value_counts()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "negative    9178\n",
              "neutral     3099\n",
              "positive    2363\n",
              "Name: airline_sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 730
        },
        "id": "G9xjlClf4Y8Y",
        "outputId": "7d8e38af-6c50-42b6-b2ff-86eb7dffdc3d"
      },
      "source": [
        "# Lets visualize the sentiments\r\n",
        "count_classes = pd.value_counts(dataset['airline_sentiment'], sort = True)\r\n",
        "count_classes.plot(kind = 'bar', rot = 0)\r\n",
        "plt.title(\"Customer Sentiment Distribution\")\r\n",
        "plt.xticks(range(3))\r\n",
        "plt.xlabel(\"Sentiment\")\r\n",
        "plt.ylabel('Frequency')\r\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1296x864 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjZdgHY45JHr",
        "outputId": "354edb14-b92f-4ae4-a1ee-3e1f56b93683"
      },
      "source": [
        "# Let us check for missing values in both columns\r\n",
        "print(dataset.isnull().sum())\r\n",
        "\r\n",
        "missing_values = dataset.isnull().sum().sum()\r\n",
        "print('The total number of missing values in the dataframe is' , str(missing_values))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "airline_sentiment    0\n",
            "text                 0\n",
            "dtype: int64\n",
            "The total number of missing values in the dataframe is 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRkYlsNM6nzN",
        "outputId": "195a66e6-613f-4e7d-b325-6d43b7b28442"
      },
      "source": [
        "## Data Cleaning\r\n",
        "\r\n",
        "import re\r\n",
        "import nltk\r\n",
        "nltk.download('stopwords')\r\n",
        "nltk.download('wordnet')\r\n",
        "from nltk.corpus import stopwords\r\n",
        "from nltk.stem import WordNetLemmatizer\r\n",
        "corpus = []\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "for i in range(0,dataset.shape[0]):\r\n",
        "  reviews = re.sub(r\"@[A-Za-z0-9]+\", ' ', dataset['text'][i])\r\n",
        "  reviews = re.sub(r'[^a-zA-Z]', ' ',reviews)\r\n",
        "  # Removing additional whitespaces\r\n",
        "  reviews = re.sub(r\" +\", ' ', reviews)\r\n",
        "  reviews = reviews.lower()\r\n",
        "  reviews = reviews.split()\r\n",
        "  wl = WordNetLemmatizer()\r\n",
        "  review = [wl.lemmatize(word) for word in reviews if not word in set(stopwords.words('english'))]\r\n",
        "  review = ' '.join(review) \r\n",
        "  corpus.append(review)\r\n",
        " \r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbBAOaXfB80t",
        "outputId": "69266384-b09e-4d0d-8ced-f13af14c113c"
      },
      "source": [
        "# Install tensorflow\r\n",
        "try:\r\n",
        "    %tensorflow_version 2.x\r\n",
        "except Exception:\r\n",
        "    pass\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "from tensorflow.keras import layers\r\n",
        "import tensorflow_datasets as tfds\r\n",
        "print(\"Tensorflow version  :\", tf.__version__)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version  : 2.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LP0OSKBoCvpd"
      },
      "source": [
        "## STEP 2: Tokenization and Padding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADJtsjBvRrf2",
        "outputId": "91d4876c-9d2b-445d-9455-87358d22220a"
      },
      "source": [
        "# import libraries\r\n",
        "from keras.preprocessing.text import Tokenizer\r\n",
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "\r\n",
        "#\r\n",
        "NB_words = 2**10\r\n",
        "MAX_SEQ_LEN = 100   \r\n",
        "tokenizer = Tokenizer(nb_words = NB_words)\r\n",
        "tokenizer.fit_on_texts(corpus)\r\n",
        "sequences = tokenizer.texts_to_sequences(corpus)\r\n",
        "word_index = tokenizer.word_index \r\n",
        "\r\n",
        "print(\"Found unique tokens\", len(word_index))\r\n",
        "\r\n",
        "data = pad_sequences(sequences, value=0, padding=\"post\", maxlen=MAX_SEQ_LEN)\r\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/text.py:180: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
            "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found unique tokens 11850\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7qappxRV5AW",
        "outputId": "390682e7-3cfd-43a2-ab81-398df20668de"
      },
      "source": [
        "# Let us encode the labels into integers \r\n",
        "from sklearn import preprocessing \r\n",
        "  \r\n",
        "# label_encoder \r\n",
        "label_encoder = preprocessing.LabelEncoder() \r\n",
        "  \r\n",
        "# Encode labels in column 'species'. \r\n",
        "dataset['airline_sentiment']= label_encoder.fit_transform(dataset['airline_sentiment']) \r\n",
        "  \r\n",
        "dataset['airline_sentiment'].unique() "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbpYHINeUyKD",
        "outputId": "a16a1af5-64b2-4857-940e-46ed7073af31"
      },
      "source": [
        "# Split into train and validation/test set\r\n",
        "y = dataset['airline_sentiment'].values\r\n",
        "\r\n",
        "from keras.utils import  to_categorical\r\n",
        "y = to_categorical(np.asarray(y))\r\n",
        "\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "X_train, X_test, y_train, y_test = train_test_split( data, y, test_size=0.2, random_state=42)\r\n",
        "\r\n",
        "[nsample,nshape] = X_train.shape\r\n",
        "print(nsample)\r\n",
        "print(nshape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11712\n",
            "100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNtx7M0ilNDl"
      },
      "source": [
        "### Obtain Word2Vec Embdedding Matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htvMcdQAlUq0"
      },
      "source": [
        "### Obtain Glove Embedding Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZO0GeRIykMsQ",
        "outputId": "1b7b48cb-f477-4134-fac3-71d7d515d807",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# load the whole embedding into memory\r\n",
        "embeddings_index = dict()\r\n",
        "\r\n",
        "f = open('./glove.6B.100d.txt')\r\n",
        "for line in f:\r\n",
        "  values = line.split()\r\n",
        "  word = values[0]\r\n",
        "  coefs = np.asarray(values[1:], dtype = 'float32')\r\n",
        "  embeddings_index[word] = coefs\r\n",
        "f.close()\r\n",
        "\r\n",
        "\r\n",
        "print(\"Loaded word vectors\", len(embeddings_index))\r\n",
        "\r\n",
        "vocab = tokenizer.sequences_to_texts(corpus)\r\n",
        "# adding one because of 0 reservded index\r\n",
        "vocab_size = len(tokenizer.word_index) + 1\r\n",
        "\r\n",
        "print(vocab_size)\r\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded word vectors 400000\n",
            "11851\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HB6kJ_Sm9wg"
      },
      "source": [
        "# create a weight matrix for words in the training document\r\n",
        "embedding_matrix = np.zeros((vocab_size, 100))\r\n",
        "\r\n",
        "for word, i in tokenizer.word_index.items():\r\n",
        "    embedding_vector = embeddings_index.get(word)\r\n",
        "    if embedding_vector is not None:\r\n",
        "      embedding_matrix[i]= embedding_vector\r\n",
        "  "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGicKLKDbENK"
      },
      "source": [
        "## Step 3: Build and Train Model (Word2Vec)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYoJAe5sbfHr",
        "outputId": "89b667c5-3a3c-40b6-86a9-77498c251ea0"
      },
      "source": [
        "# Import keras libraries\r\n",
        "from keras.models import Sequential, Model\r\n",
        "from keras.layers import Dense,Dropout,Activation\r\n",
        "from keras.layers import Input, Flatten, Embedding, concatenate\r\n",
        "from keras.layers.recurrent import LSTM\r\n",
        "from keras.layers.wrappers import Bidirectional\r\n",
        "from keras.utils import to_categorical\r\n",
        "\r\n",
        "from IPython.display import SVG\r\n",
        "from keras.utils.vis_utils import model_to_dot\r\n",
        "\r\n",
        "print(\"Installation sucessfull!\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Installation sucessfull!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-c9XT69AbIW1",
        "outputId": "6a48331f-310b-4629-9ebe-41cde9139692"
      },
      "source": [
        "# Build Seq2Seq architecture\r\n",
        "\r\n",
        "model1 = Sequential()\r\n",
        "\r\n",
        "# Add Embedding Layer and number of output is 100 as we embedded with a 100D word2vec model\r\n",
        "Embed_layer = Embedding(input_dim= vocab_size, output_dim= 100, weights = [embedding_matrix], input_length= (MAX_SEQ_LEN,), trainable = True )\r\n",
        "\r\n",
        "# define inputs\r\n",
        "review_input = Input(shape=(MAX_SEQ_LEN,), dtype='int32', name = 'review_input')\r\n",
        "review_embedding = Embed_layer(review_input)\r\n",
        "Flatten_layer = Flatten()\r\n",
        "Flatten_review = Flatten_layer(review_embedding)\r\n",
        "output_size = 3\r\n",
        "\r\n",
        "dense1 = Dense(100, activation='relu')(Flatten_review)\r\n",
        "dense2 = Dense(32, activation='relu')(dense1)\r\n",
        "predict = Dense(output_size, activation='softmax')(dense2)\r\n",
        "\r\n",
        "\r\n",
        "model1 = Model(inputs = [review_input], outputs= [predict])\r\n",
        "model1.compile(loss=\"categorical_crossentropy\",\r\n",
        "                 optimizer=\"adam\",\r\n",
        "                 metrics=[\"categorical_accuracy\"])\r\n",
        "\r\n",
        "print(model1.summary())\r\n",
        "\r\n",
        "SVG(model_to_dot(model1).create(prog= 'dot', format ='svg'))\r\n",
        "\r\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "review_input (InputLayer)    [(None, 100)]             0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 100, 100)          1185100   \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 10000)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 100)               1000100   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                3232      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 2,188,531\n",
            "Trainable params: 2,188,531\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"547pt\" viewBox=\"0.00 0.00 172.00 410.00\" width=\"229pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1.3333 1.3333) rotate(0) translate(4 406)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-406 168,-406 168,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140481349014640 -->\n<g class=\"node\" id=\"node1\">\n<title>140481349014640</title>\n<polygon fill=\"none\" points=\"0,-365.5 0,-401.5 164,-401.5 164,-365.5 0,-365.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"82\" y=\"-379.8\">review_input: InputLayer</text>\n</g>\n<!-- 140481349013800 -->\n<g class=\"node\" id=\"node2\">\n<title>140481349013800</title>\n<polygon fill=\"none\" points=\"4,-292.5 4,-328.5 160,-328.5 160,-292.5 4,-292.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"82\" y=\"-306.8\">embedding: Embedding</text>\n</g>\n<!-- 140481349014640&#45;&gt;140481349013800 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140481349014640-&gt;140481349013800</title>\n<path d=\"M82,-365.4551C82,-357.3828 82,-347.6764 82,-338.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"85.5001,-338.5903 82,-328.5904 78.5001,-338.5904 85.5001,-338.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140481349017104 -->\n<g class=\"node\" id=\"node3\">\n<title>140481349017104</title>\n<polygon fill=\"none\" points=\"33,-219.5 33,-255.5 131,-255.5 131,-219.5 33,-219.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"82\" y=\"-233.8\">flatten: Flatten</text>\n</g>\n<!-- 140481349013800&#45;&gt;140481349017104 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140481349013800-&gt;140481349017104</title>\n<path d=\"M82,-292.4551C82,-284.3828 82,-274.6764 82,-265.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"85.5001,-265.5903 82,-255.5904 78.5001,-265.5904 85.5001,-265.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140481291333080 -->\n<g class=\"node\" id=\"node4\">\n<title>140481291333080</title>\n<polygon fill=\"none\" points=\"36,-146.5 36,-182.5 128,-182.5 128,-146.5 36,-146.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"82\" y=\"-160.8\">dense: Dense</text>\n</g>\n<!-- 140481349017104&#45;&gt;140481291333080 -->\n<g class=\"edge\" id=\"edge3\">\n<title>140481349017104-&gt;140481291333080</title>\n<path d=\"M82,-219.4551C82,-211.3828 82,-201.6764 82,-192.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"85.5001,-192.5903 82,-182.5904 78.5001,-192.5904 85.5001,-192.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140481291329832 -->\n<g class=\"node\" id=\"node5\">\n<title>140481291329832</title>\n<polygon fill=\"none\" points=\"28.5,-73.5 28.5,-109.5 135.5,-109.5 135.5,-73.5 28.5,-73.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"82\" y=\"-87.8\">dense_1: Dense</text>\n</g>\n<!-- 140481291333080&#45;&gt;140481291329832 -->\n<g class=\"edge\" id=\"edge4\">\n<title>140481291333080-&gt;140481291329832</title>\n<path d=\"M82,-146.4551C82,-138.3828 82,-128.6764 82,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"85.5001,-119.5903 82,-109.5904 78.5001,-119.5904 85.5001,-119.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140481291333192 -->\n<g class=\"node\" id=\"node6\">\n<title>140481291333192</title>\n<polygon fill=\"none\" points=\"28.5,-.5 28.5,-36.5 135.5,-36.5 135.5,-.5 28.5,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"82\" y=\"-14.8\">dense_2: Dense</text>\n</g>\n<!-- 140481291329832&#45;&gt;140481291333192 -->\n<g class=\"edge\" id=\"edge5\">\n<title>140481291329832-&gt;140481291333192</title>\n<path d=\"M82,-73.4551C82,-65.3828 82,-55.6764 82,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"85.5001,-46.5903 82,-36.5904 78.5001,-46.5904 85.5001,-46.5903\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuPl3QoHgVCC",
        "outputId": "a4521f80-cda3-4327-86b4-e45fe611e765"
      },
      "source": [
        "# Train the model\r\n",
        "model1.fit(X_train,y_train, epochs = 10, batch_size = 2**5, verbose = True, validation_data = (X_test,y_test))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "366/366 [==============================] - 11s 27ms/step - loss: 0.7602 - categorical_accuracy: 0.6813 - val_loss: 0.5760 - val_categorical_accuracy: 0.7674\n",
            "Epoch 2/10\n",
            "366/366 [==============================] - 9s 25ms/step - loss: 0.5080 - categorical_accuracy: 0.7889 - val_loss: 0.5762 - val_categorical_accuracy: 0.7702\n",
            "Epoch 3/10\n",
            "366/366 [==============================] - 9s 25ms/step - loss: 0.4078 - categorical_accuracy: 0.8352 - val_loss: 0.5878 - val_categorical_accuracy: 0.7708\n",
            "Epoch 4/10\n",
            "366/366 [==============================] - 9s 25ms/step - loss: 0.3175 - categorical_accuracy: 0.8779 - val_loss: 0.6467 - val_categorical_accuracy: 0.7561\n",
            "Epoch 5/10\n",
            "366/366 [==============================] - 10s 26ms/step - loss: 0.2423 - categorical_accuracy: 0.9130 - val_loss: 0.7681 - val_categorical_accuracy: 0.7473\n",
            "Epoch 6/10\n",
            "366/366 [==============================] - 9s 26ms/step - loss: 0.1709 - categorical_accuracy: 0.9382 - val_loss: 0.8929 - val_categorical_accuracy: 0.7415\n",
            "Epoch 7/10\n",
            "366/366 [==============================] - 9s 25ms/step - loss: 0.1244 - categorical_accuracy: 0.9583 - val_loss: 1.0698 - val_categorical_accuracy: 0.7527\n",
            "Epoch 8/10\n",
            "366/366 [==============================] - 9s 26ms/step - loss: 0.0951 - categorical_accuracy: 0.9676 - val_loss: 1.2478 - val_categorical_accuracy: 0.7469\n",
            "Epoch 9/10\n",
            "366/366 [==============================] - 9s 25ms/step - loss: 0.0739 - categorical_accuracy: 0.9740 - val_loss: 1.3412 - val_categorical_accuracy: 0.7360\n",
            "Epoch 10/10\n",
            "366/366 [==============================] - 9s 25ms/step - loss: 0.0691 - categorical_accuracy: 0.9733 - val_loss: 1.5065 - val_categorical_accuracy: 0.7459\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc45974e518>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkkb0aJdoJkI",
        "outputId": "9c083b3d-179f-4fb2-ffec-fbfc9b8f64e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Save model\r\n",
        "model1.save('Glove_10epochs_NN')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: Glove_10epochs_NN/assets\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}