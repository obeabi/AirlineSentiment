{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Airline_Covnet_BertTokenizer.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/obeabi/AirlineSentiment/blob/main/Airline_Covnet_BertTokenizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJMaZXt8yoE-"
      },
      "source": [
        "# Airline Sentiment Dataset\r\n",
        "## Written by Abiola Obembe\r\n",
        "### Date: 2020-12-31\r\n",
        "\r\n",
        "### Goal: Train a classifiier to predict customer sentiment from customer review text (using Bert tokenizer and pretrained word embeddings)\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqeNHhjp25v_"
      },
      "source": [
        "A sentiment analysis job about the problems of each major U.S. airline. Twitter data was scraped from February of 2015 and contributors were asked to first classify positive, negative, and neutral tweets, followed by categorizing negative reasons (such as \"late flight\" or \"rude service\")."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LiwXn9d50qi6"
      },
      "source": [
        "## Step 1: Data Cleaning and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woeaqOfFP10F",
        "outputId": "e8166085-fd0e-4609-b3a6-301d4cba090c"
      },
      "source": [
        "# install BERT library\r\n",
        "!pip install bert-for-tf2\r\n",
        "!pip install sentencepiece\r\n",
        "\r\n",
        "print(\"Packages installed!\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: bert-for-tf2 in /usr/local/lib/python3.6/dist-packages (0.14.7)\n",
            "Requirement already satisfied: params-flow>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from bert-for-tf2) (0.8.2)\n",
            "Requirement already satisfied: py-params>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from bert-for-tf2) (0.9.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.19.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.41.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (0.1.94)\n",
            "Packages installed!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjlZhoV_P3Uj",
        "outputId": "1c3e441f-0fb5-450c-d93a-9d74112e4f10"
      },
      "source": [
        "# Install tensorflow\r\n",
        "try:\r\n",
        "  %tensorflow_version 2.x\r\n",
        "except Exception:\r\n",
        "  pass\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "import tensorflow_hub as hub\r\n",
        "from tensorflow.keras import layers\r\n",
        "import bert\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "%matplotlib inline\r\n",
        "plt.rcParams['figure.figsize'] = (12.0, 8.0) # set default size of plots\r\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\r\n",
        "plt.rcParams['image.cmap'] = 'gray'\r\n",
        "\r\n",
        "\r\n",
        "print(\"installation complete!\")\r\n",
        "print(tf.__version__)\r\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "installation complete!\n",
            "2.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "Ru8XNKar0pGE",
        "outputId": "df04c10f-c5ef-45bc-9bca-694ebd254e21"
      },
      "source": [
        "# Import dataset\r\n",
        "dataset = pd.read_csv('Tweets.csv', encoding= 'latin1', engine='python', quoting = 1)\r\n",
        "\r\n",
        "dataset.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>airline_sentiment_confidence</th>\n",
              "      <th>negativereason</th>\n",
              "      <th>negativereason_confidence</th>\n",
              "      <th>airline</th>\n",
              "      <th>airline_sentiment_gold</th>\n",
              "      <th>name</th>\n",
              "      <th>negativereason_gold</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>text</th>\n",
              "      <th>tweet_coord</th>\n",
              "      <th>tweet_created</th>\n",
              "      <th>tweet_location</th>\n",
              "      <th>user_timezone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>570306133677760513</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>cairdin</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:35:52 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Eastern Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>570301130888122368</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.3486</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:59 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>570301083672813571</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.6837</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>yvonnalynn</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:48 -0800</td>\n",
              "      <td>Lets Play</td>\n",
              "      <td>Central Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>570301031407624196</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Bad Flight</td>\n",
              "      <td>0.7033</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:36 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>570300817074462722</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Can't Tell</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:14:45 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             tweet_id  ...               user_timezone\n",
              "0  570306133677760513  ...  Eastern Time (US & Canada)\n",
              "1  570301130888122368  ...  Pacific Time (US & Canada)\n",
              "2  570301083672813571  ...  Central Time (US & Canada)\n",
              "3  570301031407624196  ...  Pacific Time (US & Canada)\n",
              "4  570300817074462722  ...  Pacific Time (US & Canada)\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "ZXcBWVgA2_co",
        "outputId": "bba0a2f4-54f7-4f92-d788-28f4f96a6ffe"
      },
      "source": [
        "# Drop columns not required\r\n",
        "dataset.drop(columns = ['tweet_id', 'airline_sentiment_confidence', 'negativereason', 'negativereason_confidence',\r\n",
        "                        'airline', 'airline_sentiment_gold','name','negativereason_gold','retweet_count','tweet_coord',\r\n",
        "                        'tweet_created','tweet_location','user_timezone'], axis = 1, inplace = True)\r\n",
        "dataset.head(10)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neutral</td>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>positive</td>\n",
              "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neutral</td>\n",
              "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>negative</td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>negative</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>negative</td>\n",
              "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>positive</td>\n",
              "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>neutral</td>\n",
              "      <td>@VirginAmerica Really missed a prime opportuni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>positive</td>\n",
              "      <td>@virginamerica Well, I didn'tâ¦but NOW I DO! :-D</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>positive</td>\n",
              "      <td>@VirginAmerica it was amazing, and arrived an ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  airline_sentiment                                               text\n",
              "0           neutral                @VirginAmerica What @dhepburn said.\n",
              "1          positive  @VirginAmerica plus you've added commercials t...\n",
              "2           neutral  @VirginAmerica I didn't today... Must mean I n...\n",
              "3          negative  @VirginAmerica it's really aggressive to blast...\n",
              "4          negative  @VirginAmerica and it's a really big bad thing...\n",
              "5          negative  @VirginAmerica seriously would pay $30 a fligh...\n",
              "6          positive  @VirginAmerica yes, nearly every time I fly VX...\n",
              "7           neutral  @VirginAmerica Really missed a prime opportuni...\n",
              "8          positive  @virginamerica Well, I didn'tâ¦but NOW I DO! :-D\n",
              "9          positive  @VirginAmerica it was amazing, and arrived an ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghh1CI-p4MSM",
        "outputId": "bea2cfa6-af75-479d-cc19-9390dc172231"
      },
      "source": [
        "#  Investigate the number of distinct sentiments\r\n",
        "dataset['airline_sentiment'].value_counts()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "negative    9178\n",
              "neutral     3099\n",
              "positive    2363\n",
              "Name: airline_sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "G9xjlClf4Y8Y",
        "outputId": "949c6606-23be-4153-fa5b-078a3482ac94"
      },
      "source": [
        "# Lets visualize the sentiments\r\n",
        "count_classes = pd.value_counts(dataset['airline_sentiment'], sort = True)\r\n",
        "count_classes.plot(kind = 'barh', rot = 0)\r\n",
        "plt.title(\"Customer Sentiment Distribution\")\r\n",
        "plt.xticks(range(3))\r\n",
        "plt.xlabel(\"Sentiment\")\r\n",
        "plt.ylabel('Frequency')\r\n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjZdgHY45JHr",
        "outputId": "81fbd1d3-47bb-4cbc-8ba4-111db9c28eaa"
      },
      "source": [
        "# Let us check for missing values in both columns\r\n",
        "print(dataset.isnull().sum())\r\n",
        "\r\n",
        "missing_values = dataset.isnull().sum().sum()\r\n",
        "print('The total number of missing values in the dataframe is' , str(missing_values))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "airline_sentiment    0\n",
            "text                 0\n",
            "dtype: int64\n",
            "The total number of missing values in the dataframe is 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRkYlsNM6nzN"
      },
      "source": [
        "## Data Cleaning\r\n",
        "\r\n",
        "import re\r\n",
        "from bs4 import BeautifulSoup\r\n",
        "corpus = []\r\n",
        "\r\n",
        "\r\n",
        "for i in range(0,dataset.shape[0]):\r\n",
        "  reviews = BeautifulSoup(dataset['text'][i], 'lxml').get_text()\r\n",
        "  reviews = re.sub(r\"@[A-Za-z0-9]+\", ' ', reviews)\r\n",
        "  reviews = re.sub(r\"https?://[A-Za-z0-9./]+\", ' ', reviews)\r\n",
        "  reviews = re.sub(r'[^a-zA-Z]', ' ',reviews)\r\n",
        "  # Removing additional whitespaces\r\n",
        "  reviews = re.sub(r\" +\", ' ', reviews)\r\n",
        "  corpus.append(reviews)\r\n",
        "  "
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-xKQI1JTsZs",
        "outputId": "6e527d32-69ce-4c8e-823e-29a42a45a842"
      },
      "source": [
        "# Let's examine the corpus\r\n",
        "corpus[0:5]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' What said ',\n",
              " ' plus you ve added commercials to the experience tacky ',\n",
              " ' I didn t today Must mean I need to take another trip ',\n",
              " ' it s really aggressive to blast obnoxious entertainment in your guests faces they have little recourse',\n",
              " ' and it s a really big bad thing about it']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YitbsrA5TaO",
        "outputId": "893495ef-e81f-44e7-e801-dae791894305"
      },
      "source": [
        "# Let us encode the labels into integers \r\n",
        "from sklearn import preprocessing \r\n",
        "  \r\n",
        "# label_encoder \r\n",
        "label_encoder = preprocessing.LabelEncoder() \r\n",
        "  \r\n",
        "# Encode labels in column 'species'. \r\n",
        "dataset['airline_sentiment']= label_encoder.fit_transform(dataset['airline_sentiment']) \r\n",
        "  \r\n",
        "dataset['airline_sentiment'].unique() "
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "6BwCr53qwTGP",
        "outputId": "cb3e97f9-d34a-4c5e-c6d7-bb8753af7d63"
      },
      "source": [
        "dataset.head()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   airline_sentiment                                               text\n",
              "0                  1                @VirginAmerica What @dhepburn said.\n",
              "1                  2  @VirginAmerica plus you've added commercials t...\n",
              "2                  1  @VirginAmerica I didn't today... Must mean I n...\n",
              "3                  0  @VirginAmerica it's really aggressive to blast...\n",
              "4                  0  @VirginAmerica and it's a really big bad thing..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LP0OSKBoCvpd"
      },
      "source": [
        "## STEP 2: Tokenization with BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64a3R48BCzys"
      },
      "source": [
        "# Tokenization: BERT\r\n",
        "FullTokenizer = bert.bert_tokenization.FullTokenizer\r\n",
        "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-256_A-4/1\", trainable= False)\r\n",
        "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\r\n",
        "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\r\n",
        "\r\n",
        "tokenizer = FullTokenizer(vocab_file, do_lower_case)\r\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dY6Ed8-hpiB2"
      },
      "source": [
        "# Create function to tokenize text\r\n",
        "def encode_sentence(sent):\r\n",
        "  return tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sent))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyMO1g0JqDlF"
      },
      "source": [
        "data_inputs = [encode_sentence(sentence) for sentence in corpus ]"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hv8sGp4bYKyh",
        "outputId": "40ff332d-e045-4f24-a5ea-804d5885c0c5"
      },
      "source": [
        "# Let's examine the tokenizer in action\r\n",
        "encode_sentence(\"My dog loves oranges.\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2026, 3899, 7459, 4589, 2015, 1012]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LANNz6mIlcbt",
        "outputId": "7c60fe85-00cf-4a3f-b97c-a9ea581a9d20"
      },
      "source": [
        "# Let's examine the tokenizer in action\r\n",
        "encode_sentence(\"Dogs loves bones but hates oranges.\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[6077, 7459, 5944, 2021, 16424, 4589, 2015, 1012]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BB1FKQh8ZRjD"
      },
      "source": [
        "# create dataset\r\n",
        "data_labels = dataset.airline_sentiment.values\r\n",
        "\r\n",
        "data_with_len = [[sent, data_labels[i], len(sent)]\r\n",
        "                 for i, sent in enumerate(data_inputs)]\r\n",
        "\r\n",
        "np.random.shuffle(data_with_len)\r\n",
        "data_with_len.sort(key= lambda x: x[2])\r\n",
        "\r\n",
        "sorted_all = [(sent_lab[0], sent_lab[1])\r\n",
        "\r\n",
        "              for sent_lab in data_with_len if sent_lab[2]> 2]\r\n",
        "\r\n",
        "all_dataset = tf.data.Dataset.from_generator(lambda: sorted_all,\r\n",
        "                                             output_types = (tf.int32, tf.int32))\r\n",
        "\r\n",
        "BATCH_SIZE = 32\r\n",
        "all_batched = all_dataset.padded_batch(BATCH_SIZE, padded_shapes= ((None,), ()   ))\r\n",
        "\r\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awOU9HJwfGMU",
        "outputId": "04961f77-45bf-42eb-ebe8-ce80da329b3c"
      },
      "source": [
        "# Inspect dataset\r\n",
        "next(iter(all_batched))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(32, 3), dtype=int32, numpy=\n",
              " array([[ 2205,  2397,  3462],\n",
              "        [ 1040,  2213,  2741],\n",
              "        [ 2017,  2128,  6160],\n",
              "        [ 2206,  2026,  2919],\n",
              "        [ 2469,  4067,  2017],\n",
              "        [18168,  2290,  2633],\n",
              "        [ 1045,  2066,  3582],\n",
              "        [ 2017,  4364, 11891],\n",
              "        [ 5319,  4283,  4312],\n",
              "        [ 1040,  2213,  2741],\n",
              "        [ 2115,  2326, 19237],\n",
              "        [ 2017,  4364,  2600],\n",
              "        [ 4283,  2033,  2205],\n",
              "        [ 2589,  2004,  7303],\n",
              "        [ 2307,  4067,  2017],\n",
              "        [ 2017,  2024,  6659],\n",
              "        [ 2288,  2009,  4283],\n",
              "        [ 2763,  2025,  4902],\n",
              "        [ 5409,  3325,  2412],\n",
              "        [ 7929,  4067,  2017],\n",
              "        [ 2748,  2064,  2079],\n",
              "        [ 2323,  1045,  3613],\n",
              "        [ 2074,  2741,  2009],\n",
              "        [ 2054,  2055,  3462],\n",
              "        [ 2053,  2272,  2006],\n",
              "        [ 2202,  2033,  2182],\n",
              "        [ 2053, 13204,  2015],\n",
              "        [ 2026, 10007, 13403],\n",
              "        [ 2017,  8239, 11891],\n",
              "        [ 2307,  4067,  2017],\n",
              "        [ 1057,  4364, 11891],\n",
              "        [ 4067,  2017, 19045]], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([0, 1, 2, 1, 2, 2, 2, 0, 2, 1, 0, 2, 2, 1, 2, 0, 2, 1, 0, 2, 1, 0,\n",
              "        0, 1, 1, 1, 0, 0, 0, 2, 0, 2], dtype=int32)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1Dvw1dXL84Z"
      },
      "source": [
        "# split dataset into train and test set\r\n",
        "import math\r\n",
        "NB_BATCHES = math.ceil(len(sorted_all)/BATCH_SIZE)\r\n",
        "NB_BATCHES_TEST = NB_BATCHES// 10\r\n",
        "all_batched.shuffle(NB_BATCHES)\r\n",
        "test_dataset = all_batched.take(NB_BATCHES_TEST)\r\n",
        "train_dataset = all_batched.skip(NB_BATCHES_TEST)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MeKHgAnNAbe"
      },
      "source": [
        "# Step 4: Build the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3E2QXV-NM0G"
      },
      "source": [
        "class DCNN(tf.keras.Model):\r\n",
        "    \r\n",
        "    def __init__(self,\r\n",
        "                 vocab_size,\r\n",
        "                 emb_dim=128,\r\n",
        "                 nb_filters=50,\r\n",
        "                 FFN_units=512,\r\n",
        "                 nb_classes=2,\r\n",
        "                 dropout_rate=0.1,\r\n",
        "                 training=False,\r\n",
        "                 name=\"dcnn\"):\r\n",
        "        super(DCNN, self).__init__(name=name)\r\n",
        "        \r\n",
        "        self.embedding = layers.Embedding(vocab_size,emb_dim)\r\n",
        "\r\n",
        "        self.bigram = layers.Conv1D(filters=nb_filters, kernel_size=2, padding=\"valid\", activation=\"relu\")\r\n",
        "        \r\n",
        "        self.trigram = layers.Conv1D(filters=nb_filters,kernel_size=3, padding=\"valid\", activation=\"relu\")\r\n",
        "        \r\n",
        "        self.fourgram = layers.Conv1D(filters=nb_filters, kernel_size=4, padding=\"valid\", activation=\"relu\")\r\n",
        "        \r\n",
        "        self.pool = layers.GlobalMaxPool1D() # no training variable so we can\r\n",
        "                                             # use the same layer for each\r\n",
        "                                             # pooling step\r\n",
        "        self.dense_1 = layers.Dense(units=FFN_units, activation=\"relu\")\r\n",
        "        self.dropout = layers.Dropout(rate=dropout_rate)\r\n",
        "        \r\n",
        "        if nb_classes == 2:\r\n",
        "            self.last_dense = layers.Dense(units=1, activation=\"sigmoid\")\r\n",
        "        else:\r\n",
        "            self.last_dense = layers.Dense(units=nb_classes, activation=\"softmax\")\r\n",
        "\r\n",
        "    def call(self, inputs, training):\r\n",
        "        x = self.embedding(inputs)\r\n",
        "        x_1 = self.bigram(x)\r\n",
        "        x_1 = self.pool(x_1)\r\n",
        "        x_2 = self.trigram(x)\r\n",
        "        x_2 = self.pool(x_2)\r\n",
        "        x_3 = self.fourgram(x)\r\n",
        "        x_3 = self.pool(x_3)\r\n",
        "        \r\n",
        "        merged = tf.concat([x_1, x_2, x_3], axis=-1) # (batch_size, 3 * nb_filters)\r\n",
        "        merged = self.dense_1(merged)\r\n",
        "        merged = self.dropout(merged, training)\r\n",
        "        output = self.last_dense(merged)\r\n",
        "        \r\n",
        "        return output"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoL7PvuQNbDZ"
      },
      "source": [
        "# Configuration details\r\n",
        "VOCAB_SIZE = len(tokenizer.vocab)\r\n",
        "\r\n",
        "EMB_DIM = 200\r\n",
        "NB_FILTERS = 100\r\n",
        "FFN_UNITS = 256\r\n",
        "NB_CLASSES = 3\r\n",
        "\r\n",
        "DROPOUT_RATE = 0.25\r\n",
        "\r\n",
        "NB_EPOCHS = 10"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXiP6189NtEg"
      },
      "source": [
        "# Let's DEFINE THE LOSS for the model\r\n",
        "Dcnn = DCNN(vocab_size=VOCAB_SIZE,\r\n",
        "            emb_dim=EMB_DIM,\r\n",
        "            nb_filters=NB_FILTERS,\r\n",
        "            FFN_units=FFN_UNITS,\r\n",
        "            nb_classes=NB_CLASSES,\r\n",
        "            dropout_rate=DROPOUT_RATE)\r\n",
        "\r\n",
        "if NB_CLASSES == 2:\r\n",
        "    Dcnn.compile(loss=\"binary_crossentropy\",\r\n",
        "                 optimizer=\"adam\",\r\n",
        "                 metrics=[\"accuracy\"])\r\n",
        "else:\r\n",
        "    Dcnn.compile(loss=\"sparse_categorical_crossentropy\",\r\n",
        "                 optimizer=\"adam\",\r\n",
        "                 metrics=[\"sparse_categorical_accuracy\"])"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkckNQU4mSWU"
      },
      "source": [
        "# Create a checkpoint\r\n",
        "checkpoint_path = \"./drive/My Drive/projects/Bert_for_NLP/ckpt/\"\r\n",
        "\r\n",
        "ckpt = tf.train.Checkpoint(Dcnn=Dcnn)\r\n",
        "\r\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\r\n",
        "\r\n",
        "if ckpt_manager.latest_checkpoint:\r\n",
        "    ckpt.restore(ckpt_manager.latest_checkpoint)\r\n",
        "    print(\"Latest checkpoint restored!!\")\r\n",
        "\r\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZxBHbGNm_hI"
      },
      "source": [
        "class MyCustomCallback(tf.keras.callbacks.Callback):\r\n",
        "\r\n",
        "   def on_epoch_end(self, epoch, logs = None):\r\n",
        "     ckpt_manager.save()\r\n",
        "     print(\"Checkpoint saved at {}. \".format(checkpoint_path))"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHvuNVEcNwH-",
        "outputId": "549d48c9-2968-4ec1-dffd-1bff573b89ee"
      },
      "source": [
        "# train model\r\n",
        "Dcnn.fit(train_dataset,epochs=NB_EPOCHS, callbacks= [MyCustomCallback()])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "404/404 [==============================] - 34s 82ms/step - loss: 0.7809 - sparse_categorical_accuracy: 0.6250\n",
            "Checkpoint saved at ./drive/My Drive/projects/Bert_for_NLP/ckpt/. \n",
            "Epoch 2/10\n",
            "404/404 [==============================] - 34s 83ms/step - loss: 0.4517 - sparse_categorical_accuracy: 0.8220\n",
            "Checkpoint saved at ./drive/My Drive/projects/Bert_for_NLP/ckpt/. \n",
            "Epoch 3/10\n",
            "404/404 [==============================] - 34s 83ms/step - loss: 0.2370 - sparse_categorical_accuracy: 0.9162\n",
            "Checkpoint saved at ./drive/My Drive/projects/Bert_for_NLP/ckpt/. \n",
            "Epoch 4/10\n",
            "404/404 [==============================] - 33s 82ms/step - loss: 0.1227 - sparse_categorical_accuracy: 0.9596\n",
            "Checkpoint saved at ./drive/My Drive/projects/Bert_for_NLP/ckpt/. \n",
            "Epoch 5/10\n",
            "404/404 [==============================] - 34s 83ms/step - loss: 0.0795 - sparse_categorical_accuracy: 0.9751\n",
            "Checkpoint saved at ./drive/My Drive/projects/Bert_for_NLP/ckpt/. \n",
            "Epoch 6/10\n",
            "404/404 [==============================] - 33s 82ms/step - loss: 0.0639 - sparse_categorical_accuracy: 0.9812\n",
            "Checkpoint saved at ./drive/My Drive/projects/Bert_for_NLP/ckpt/. \n",
            "Epoch 7/10\n",
            "404/404 [==============================] - 33s 82ms/step - loss: 0.0446 - sparse_categorical_accuracy: 0.9869\n",
            "Checkpoint saved at ./drive/My Drive/projects/Bert_for_NLP/ckpt/. \n",
            "Epoch 8/10\n",
            "404/404 [==============================] - 34s 83ms/step - loss: 0.0287 - sparse_categorical_accuracy: 0.9920\n",
            "Checkpoint saved at ./drive/My Drive/projects/Bert_for_NLP/ckpt/. \n",
            "Epoch 9/10\n",
            "404/404 [==============================] - 34s 84ms/step - loss: 0.0180 - sparse_categorical_accuracy: 0.9958\n",
            "Checkpoint saved at ./drive/My Drive/projects/Bert_for_NLP/ckpt/. \n",
            "Epoch 10/10\n",
            "404/404 [==============================] - 34s 83ms/step - loss: 0.0150 - sparse_categorical_accuracy: 0.9963\n",
            "Checkpoint saved at ./drive/My Drive/projects/Bert_for_NLP/ckpt/. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa691f4ed30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5svksYtNOBM4",
        "outputId": "a8f9ee24-5c3e-4fd7-a9d3-e7ab63206ece"
      },
      "source": [
        "# Evaluate model\r\n",
        "results = Dcnn.evaluate(test_dataset)\r\n",
        "print(results)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "44/44 [==============================] - 1s 9ms/step - loss: 1.2804 - sparse_categorical_accuracy: 0.6911\n",
            "[1.2803740501403809, 0.6910511255264282]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DYl2Vqqq3N4"
      },
      "source": [
        "# Make predictions\r\n",
        "def get_prediction(sentence):\r\n",
        "  tokens = encode_sentence(sentence)\r\n",
        "  inputs = tf.expand_dims(tokens, 0)\r\n",
        "\r\n",
        "  output = Dcnn(inputs, training= False)\r\n",
        "  sentiment = output\r\n",
        "\r\n",
        "  for i in range(len(sentiment)):\r\n",
        "    if np.argmax(sentiment) == 0:\r\n",
        "      print(\"The sentiment is positive\")\r\n",
        "\r\n",
        "    elif np.argmax(sentiment) == 1:\r\n",
        "      print(\"The sentiment is negative\")\r\n",
        "\r\n",
        "    else:\r\n",
        "        print('The sentiment is neutral')\r\n"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WELSHlkFtZ0T",
        "outputId": "a4c51350-2143-4cdb-c809-11446ee58e73"
      },
      "source": [
        "x= get_prediction(\"I'd rather not do that agaian.\")\r\n"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The sentiment is positive\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}