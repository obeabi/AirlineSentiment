{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Airline_NN_Word2Vec.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNaqIvUfUXbcAwTOJXedbHR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/obeabi/AirlineSentiment/blob/main/Airline_NN_Word2Vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJMaZXt8yoE-"
      },
      "source": [
        "# Airline Sentiment Dataset\r\n",
        "## Written by Abiola Obembe\r\n",
        "### Date: 2020-12-24\r\n",
        "\r\n",
        "### Goal: Train a classifiier to predict customer sentiment from customer review text (using NN and pretrained word embeddings i.e. word2vec and glove)\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqeNHhjp25v_"
      },
      "source": [
        "A sentiment analysis job about the problems of each major U.S. airline. Twitter data was scraped from February of 2015 and contributors were asked to first classify positive, negative, and neutral tweets, followed by categorizing negative reasons (such as \"late flight\" or \"rude service\")."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LiwXn9d50qi6"
      },
      "source": [
        "## Step 1: Data Cleaning and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCi0HP5szMY8",
        "outputId": "3c56c2c0-d393-4118-db64-4cb92653867b"
      },
      "source": [
        "# install libraries\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "%matplotlib inline\r\n",
        "plt.rcParams['figure.figsize'] = (18.0, 12.0) # set default size of plots\r\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\r\n",
        "plt.rcParams['image.cmap'] = 'gray'\r\n",
        "\r\n",
        "\r\n",
        "print(\"installation complete!\")\r\n"
      ],
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "installation complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "Ru8XNKar0pGE",
        "outputId": "343ce951-0bc5-4e0d-91f1-56b834f1afbb"
      },
      "source": [
        "# Import dataset\r\n",
        "dataset = pd.read_csv('Tweets.csv', encoding= 'latin1', engine='python', quoting = 1)\r\n",
        "\r\n",
        "dataset.head()"
      ],
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>airline_sentiment_confidence</th>\n",
              "      <th>negativereason</th>\n",
              "      <th>negativereason_confidence</th>\n",
              "      <th>airline</th>\n",
              "      <th>airline_sentiment_gold</th>\n",
              "      <th>name</th>\n",
              "      <th>negativereason_gold</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>text</th>\n",
              "      <th>tweet_coord</th>\n",
              "      <th>tweet_created</th>\n",
              "      <th>tweet_location</th>\n",
              "      <th>user_timezone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>570306133677760513</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>cairdin</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:35:52 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Eastern Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>570301130888122368</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.3486</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:59 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>570301083672813571</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.6837</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>yvonnalynn</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:48 -0800</td>\n",
              "      <td>Lets Play</td>\n",
              "      <td>Central Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>570301031407624196</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Bad Flight</td>\n",
              "      <td>0.7033</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:36 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>570300817074462722</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Can't Tell</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:14:45 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             tweet_id  ...               user_timezone\n",
              "0  570306133677760513  ...  Eastern Time (US & Canada)\n",
              "1  570301130888122368  ...  Pacific Time (US & Canada)\n",
              "2  570301083672813571  ...  Central Time (US & Canada)\n",
              "3  570301031407624196  ...  Pacific Time (US & Canada)\n",
              "4  570300817074462722  ...  Pacific Time (US & Canada)\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 202
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "ZXcBWVgA2_co",
        "outputId": "890abc48-5415-4fa0-e88c-1f86478f55c6"
      },
      "source": [
        "# Drop columns not required\r\n",
        "dataset.drop(columns = ['tweet_id', 'airline_sentiment_confidence', 'negativereason', 'negativereason_confidence',\r\n",
        "                        'airline', 'airline_sentiment_gold','name','negativereason_gold','retweet_count','tweet_coord',\r\n",
        "                        'tweet_created','tweet_location','user_timezone'], axis = 1, inplace = True)\r\n",
        "dataset.head(10)"
      ],
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neutral</td>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>positive</td>\n",
              "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neutral</td>\n",
              "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>negative</td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>negative</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>negative</td>\n",
              "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>positive</td>\n",
              "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>neutral</td>\n",
              "      <td>@VirginAmerica Really missed a prime opportuni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>positive</td>\n",
              "      <td>@virginamerica Well, I didn'tâ¦but NOW I DO! :-D</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>positive</td>\n",
              "      <td>@VirginAmerica it was amazing, and arrived an ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  airline_sentiment                                               text\n",
              "0           neutral                @VirginAmerica What @dhepburn said.\n",
              "1          positive  @VirginAmerica plus you've added commercials t...\n",
              "2           neutral  @VirginAmerica I didn't today... Must mean I n...\n",
              "3          negative  @VirginAmerica it's really aggressive to blast...\n",
              "4          negative  @VirginAmerica and it's a really big bad thing...\n",
              "5          negative  @VirginAmerica seriously would pay $30 a fligh...\n",
              "6          positive  @VirginAmerica yes, nearly every time I fly VX...\n",
              "7           neutral  @VirginAmerica Really missed a prime opportuni...\n",
              "8          positive  @virginamerica Well, I didn'tâ¦but NOW I DO! :-D\n",
              "9          positive  @VirginAmerica it was amazing, and arrived an ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 203
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghh1CI-p4MSM",
        "outputId": "e8aa6bb2-3452-4e67-8ddc-eacc4f619770"
      },
      "source": [
        "#  Investigate the number of distinct sentiments\r\n",
        "dataset['airline_sentiment'].value_counts()"
      ],
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "negative    9178\n",
              "neutral     3099\n",
              "positive    2363\n",
              "Name: airline_sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 204
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 730
        },
        "id": "G9xjlClf4Y8Y",
        "outputId": "f5d8b88e-0ef0-467c-ba36-7de556a94983"
      },
      "source": [
        "# Lets visualize the sentiments\r\n",
        "count_classes = pd.value_counts(dataset['airline_sentiment'], sort = True)\r\n",
        "count_classes.plot(kind = 'bar', rot = 0)\r\n",
        "plt.title(\"Customer Sentiment Distribution\")\r\n",
        "plt.xticks(range(3))\r\n",
        "plt.xlabel(\"Sentiment\")\r\n",
        "plt.ylabel('Frequency')\r\n",
        "plt.show()"
      ],
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1296x864 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjZdgHY45JHr",
        "outputId": "399691ab-744e-4ed0-e9b4-afb75159c7bf"
      },
      "source": [
        "# Let us check for missing values in both columns\r\n",
        "print(dataset.isnull().sum())\r\n",
        "\r\n",
        "missing_values = dataset.isnull().sum().sum()\r\n",
        "print('The total number of missing values in the dataframe is' , str(missing_values))"
      ],
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "airline_sentiment    0\n",
            "text                 0\n",
            "dtype: int64\n",
            "The total number of missing values in the dataframe is 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRkYlsNM6nzN",
        "outputId": "b953ba50-a561-4129-c5c1-5748d8fb3e9d"
      },
      "source": [
        "## Data Cleaning\r\n",
        "\r\n",
        "import re\r\n",
        "import nltk\r\n",
        "nltk.download('stopwords')\r\n",
        "nltk.download('wordnet')\r\n",
        "from nltk.corpus import stopwords\r\n",
        "from nltk.stem import WordNetLemmatizer\r\n",
        "corpus = []\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "for i in range(0,dataset.shape[0]):\r\n",
        "  reviews = re.sub(r\"@[A-Za-z0-9]+\", ' ', dataset['text'][i])\r\n",
        "  reviews = re.sub(r'[^a-zA-Z]', ' ',reviews)\r\n",
        "  # Removing additional whitespaces\r\n",
        "  reviews = re.sub(r\" +\", ' ', reviews)\r\n",
        "  reviews = reviews.lower()\r\n",
        "  reviews = reviews.split()\r\n",
        "  wl = WordNetLemmatizer()\r\n",
        "  review = [wl.lemmatize(word) for word in reviews if not word in set(stopwords.words('english'))]\r\n",
        "  review = ' '.join(review) \r\n",
        "  corpus.append(review)\r\n",
        " \r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbBAOaXfB80t",
        "outputId": "6bfb43e2-624c-4337-c3ce-fb27c06b5d0c"
      },
      "source": [
        "# Install tensorflow\r\n",
        "try:\r\n",
        "    %tensorflow_version 2.x\r\n",
        "except Exception:\r\n",
        "    pass\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "from tensorflow.keras import layers\r\n",
        "import tensorflow_datasets as tfds\r\n",
        "print(\"Tensorflow version  :\", tf.__version__)"
      ],
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version  : 2.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LP0OSKBoCvpd"
      },
      "source": [
        "## STEP 2: Tokenization and Padding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADJtsjBvRrf2",
        "outputId": "ad02509c-d556-4691-e61c-bb003b8392c5"
      },
      "source": [
        "# import libraries\r\n",
        "from keras.preprocessing.text import Tokenizer\r\n",
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "\r\n",
        "#\r\n",
        "NB_words = 2**10\r\n",
        "MAX_SEQ_LEN = 100   \r\n",
        "tokenizer = Tokenizer(nb_words = NB_words)\r\n",
        "tokenizer.fit_on_texts(corpus)\r\n",
        "sequences = tokenizer.texts_to_sequences(corpus)\r\n",
        "word_index = tokenizer.word_index \r\n",
        "\r\n",
        "print(\"Found unique tokens\", len(word_index))\r\n",
        "\r\n",
        "data = pad_sequences(sequences, value=0, padding=\"post\", maxlen=MAX_SEQ_LEN)\r\n"
      ],
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/text.py:180: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
            "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found unique tokens 11850\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7qappxRV5AW",
        "outputId": "14e58eca-246a-4b89-8f09-97d1e367247b"
      },
      "source": [
        "# Let us encode the labels into integers \r\n",
        "from sklearn import preprocessing \r\n",
        "  \r\n",
        "# label_encoder \r\n",
        "label_encoder = preprocessing.LabelEncoder() \r\n",
        "  \r\n",
        "# Encode labels in column 'species'. \r\n",
        "dataset['airline_sentiment']= label_encoder.fit_transform(dataset['airline_sentiment']) \r\n",
        "  \r\n",
        "dataset['airline_sentiment'].unique() "
      ],
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbpYHINeUyKD",
        "outputId": "d842a22f-cd67-48f4-ec9f-4d8777864e97"
      },
      "source": [
        "# Split into train and validation/test set\r\n",
        "y = dataset['airline_sentiment'].values\r\n",
        "\r\n",
        "from keras.utils import  to_categorical\r\n",
        "y = to_categorical(np.asarray(y))\r\n",
        "\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "X_train, X_test, y_train, y_test = train_test_split( data, y, test_size=0.2, random_state=42)\r\n",
        "\r\n",
        "[nsample,nshape] = X_train.shape\r\n",
        "print(nsample)\r\n",
        "print(nshape)"
      ],
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11712\n",
            "100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htvMcdQAlUq0"
      },
      "source": [
        "### Obtain Word2Vec Embedding Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZO0GeRIykMsQ"
      },
      "source": [
        "# Now we need to get the pre-trained vectors for the word2vec embeddings\r\n",
        "import gensim\r\n",
        "import gensim.downloader as api\r\n",
        "\r\n",
        "embeddings_ap = api.load(\"glove-wiki-gigaword-100\") \r\n"
      ],
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYfIQ7i0p4yH",
        "outputId": "8e1163e5-f687-48da-d222-5dac608ab7d5"
      },
      "source": [
        "# After this we create an embedding matrix for the tokenized text for the reviews\r\n",
        "vocab = tokenizer.texts_to_sequences(corpus)\r\n",
        "\r\n",
        "# added one due to reserved index\r\n",
        "vocab_size = len(tokenizer.word_index) + 1\r\n",
        "print(vocab_size)\r\n",
        "\r\n",
        "# create a weight matrix for words in the training document\r\n",
        "embedding_matrix = np.zeros((vocab_size, 100))\r\n",
        "\r\n",
        "for word, i in tokenizer.word_index.items():\r\n",
        "  try:\r\n",
        "    embedding_vector = embeddings_ap[word]\r\n",
        "    if embedding_vector is not None:\r\n",
        "        embedding_matrix[i] = embedding_vector\r\n",
        "  except:\r\n",
        "    pass"
      ],
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11851\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Evmq4e1LqANh",
        "outputId": "75cde98a-aec5-4d8a-f6fc-e41d20d940d0"
      },
      "source": [
        "# print embedding matrix\r\n",
        "embedding_matrix"
      ],
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 0.1219    , -0.65645999,  0.50854999, ..., -0.23317   ,\n",
              "        -0.013865  , -0.78455001],\n",
              "       [ 0.14432999,  0.43950999,  0.58323997, ...,  0.50133997,\n",
              "         0.49535999,  0.49919999],\n",
              "       ...,\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [-0.24322   , -0.80457997,  0.098619  , ..., -0.42359   ,\n",
              "         0.35133001,  0.19468001],\n",
              "       [-0.29222   , -0.53171003,  0.15395001, ..., -0.28490001,\n",
              "         0.99054003,  0.1701    ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 214
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGicKLKDbENK"
      },
      "source": [
        "## Step 3: Build and Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYoJAe5sbfHr",
        "outputId": "e520662a-b91d-496f-9f67-5902024bf98d"
      },
      "source": [
        "# Import keras libraries\r\n",
        "from keras.models import Sequential, Model\r\n",
        "from keras.layers import Dense,Dropout,Activation\r\n",
        "from keras.layers import Input, Flatten, Embedding, concatenate\r\n",
        "from keras.layers.recurrent import LSTM\r\n",
        "from keras.layers.wrappers import Bidirectional\r\n",
        "from keras.utils import to_categorical\r\n",
        "\r\n",
        "from IPython.display import SVG\r\n",
        "from keras.utils.vis_utils import model_to_dot\r\n",
        "\r\n",
        "print(\"Installation sucessfull!\")"
      ],
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Installation sucessfull!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-c9XT69AbIW1",
        "outputId": "82311413-9681-46cd-9da1-3c5d7619a0e8"
      },
      "source": [
        "# Build Seq2Seq architecture\r\n",
        "\r\n",
        "model1 = Sequential()\r\n",
        "\r\n",
        "# Add Embedding Layer and number of output is 100 as we embedded with a 100D word2vec model\r\n",
        "Embed_layer = Embedding(input_dim= vocab_size, output_dim= 100, weights = [embedding_matrix], input_length= (MAX_SEQ_LEN,), trainable = True )\r\n",
        "\r\n",
        "# define inputs\r\n",
        "review_input = Input(shape=(MAX_SEQ_LEN,), dtype='int32', name = 'review_input')\r\n",
        "review_embedding = Embed_layer(review_input)\r\n",
        "Flatten_layer = Flatten()\r\n",
        "Flatten_review = Flatten_layer(review_embedding)\r\n",
        "output_size = 3\r\n",
        "\r\n",
        "dense1 = Dense(100, activation='relu')(Flatten_review)\r\n",
        "dense1 = Dropout(0.25)(dense1)\r\n",
        "dense2 = Dense(64, activation='relu')(dense1)\r\n",
        "dense2 = Dropout(0.4)(dense2)\r\n",
        "dense3 = Dense(32, activation='relu')(dense2)\r\n",
        "dense3 = Dropout(0.5)(dense3)\r\n",
        "predict = Dense(output_size, activation='softmax')(dense3)\r\n",
        "\r\n",
        "\r\n",
        "model1 = Model(inputs = [review_input], outputs= [predict])\r\n",
        "model1.compile(loss=\"categorical_crossentropy\",\r\n",
        "                 optimizer=\"adam\",\r\n",
        "                 metrics=[\"categorical_accuracy\"])\r\n",
        "\r\n",
        "print(model1.summary())\r\n",
        "\r\n",
        "SVG(model_to_dot(model1).create(prog= 'dot', format ='svg'))\r\n",
        "\r\n"
      ],
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_14\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "review_input (InputLayer)    [(None, 100)]             0         \n",
            "_________________________________________________________________\n",
            "embedding_23 (Embedding)     (None, 100, 100)          1185100   \n",
            "_________________________________________________________________\n",
            "flatten_18 (Flatten)         (None, 10000)             0         \n",
            "_________________________________________________________________\n",
            "dense_62 (Dense)             (None, 100)               1000100   \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_63 (Dense)             (None, 64)                6464      \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_64 (Dense)             (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_65 (Dense)             (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 2,193,843\n",
            "Trainable params: 2,193,843\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"936pt\" viewBox=\"0.00 0.00 187.00 702.00\" width=\"249pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1.3333 1.3333) rotate(0) translate(4 698)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-698 183,-698 183,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140231658777344 -->\n<g class=\"node\" id=\"node1\">\n<title>140231658777344</title>\n<polygon fill=\"none\" points=\"7.5,-657.5 7.5,-693.5 171.5,-693.5 171.5,-657.5 7.5,-657.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"89.5\" y=\"-671.8\">review_input: InputLayer</text>\n</g>\n<!-- 140231658775832 -->\n<g class=\"node\" id=\"node2\">\n<title>140231658775832</title>\n<polygon fill=\"none\" points=\"0,-584.5 0,-620.5 179,-620.5 179,-584.5 0,-584.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"89.5\" y=\"-598.8\">embedding_23: Embedding</text>\n</g>\n<!-- 140231658777344&#45;&gt;140231658775832 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140231658777344-&gt;140231658775832</title>\n<path d=\"M89.5,-657.4551C89.5,-649.3828 89.5,-639.6764 89.5,-630.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"93.0001,-630.5903 89.5,-620.5904 86.0001,-630.5904 93.0001,-630.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140231699841936 -->\n<g class=\"node\" id=\"node3\">\n<title>140231699841936</title>\n<polygon fill=\"none\" points=\"29,-511.5 29,-547.5 150,-547.5 150,-511.5 29,-511.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"89.5\" y=\"-525.8\">flatten_18: Flatten</text>\n</g>\n<!-- 140231658775832&#45;&gt;140231699841936 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140231658775832-&gt;140231699841936</title>\n<path d=\"M89.5,-584.4551C89.5,-576.3828 89.5,-566.6764 89.5,-557.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"93.0001,-557.5903 89.5,-547.5904 86.0001,-557.5904 93.0001,-557.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140231658778016 -->\n<g class=\"node\" id=\"node4\">\n<title>140231658778016</title>\n<polygon fill=\"none\" points=\"32.5,-438.5 32.5,-474.5 146.5,-474.5 146.5,-438.5 32.5,-438.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"89.5\" y=\"-452.8\">dense_62: Dense</text>\n</g>\n<!-- 140231699841936&#45;&gt;140231658778016 -->\n<g class=\"edge\" id=\"edge3\">\n<title>140231699841936-&gt;140231658778016</title>\n<path d=\"M89.5,-511.4551C89.5,-503.3828 89.5,-493.6764 89.5,-484.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"93.0001,-484.5903 89.5,-474.5904 86.0001,-484.5904 93.0001,-484.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140231657343856 -->\n<g class=\"node\" id=\"node5\">\n<title>140231657343856</title>\n<polygon fill=\"none\" points=\"19,-365.5 19,-401.5 160,-401.5 160,-365.5 19,-365.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"89.5\" y=\"-379.8\">dropout_12: Dropout</text>\n</g>\n<!-- 140231658778016&#45;&gt;140231657343856 -->\n<g class=\"edge\" id=\"edge4\">\n<title>140231658778016-&gt;140231657343856</title>\n<path d=\"M89.5,-438.4551C89.5,-430.3828 89.5,-420.6764 89.5,-411.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"93.0001,-411.5903 89.5,-401.5904 86.0001,-411.5904 93.0001,-411.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140231700388944 -->\n<g class=\"node\" id=\"node6\">\n<title>140231700388944</title>\n<polygon fill=\"none\" points=\"32.5,-292.5 32.5,-328.5 146.5,-328.5 146.5,-292.5 32.5,-292.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"89.5\" y=\"-306.8\">dense_63: Dense</text>\n</g>\n<!-- 140231657343856&#45;&gt;140231700388944 -->\n<g class=\"edge\" id=\"edge5\">\n<title>140231657343856-&gt;140231700388944</title>\n<path d=\"M89.5,-365.4551C89.5,-357.3828 89.5,-347.6764 89.5,-338.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"93.0001,-338.5903 89.5,-328.5904 86.0001,-338.5904 93.0001,-338.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140231700389392 -->\n<g class=\"node\" id=\"node7\">\n<title>140231700389392</title>\n<polygon fill=\"none\" points=\"19,-219.5 19,-255.5 160,-255.5 160,-219.5 19,-219.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"89.5\" y=\"-233.8\">dropout_13: Dropout</text>\n</g>\n<!-- 140231700388944&#45;&gt;140231700389392 -->\n<g class=\"edge\" id=\"edge6\">\n<title>140231700388944-&gt;140231700389392</title>\n<path d=\"M89.5,-292.4551C89.5,-284.3828 89.5,-274.6764 89.5,-265.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"93.0001,-265.5903 89.5,-255.5904 86.0001,-265.5904 93.0001,-265.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140231657313168 -->\n<g class=\"node\" id=\"node8\">\n<title>140231657313168</title>\n<polygon fill=\"none\" points=\"32.5,-146.5 32.5,-182.5 146.5,-182.5 146.5,-146.5 32.5,-146.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"89.5\" y=\"-160.8\">dense_64: Dense</text>\n</g>\n<!-- 140231700389392&#45;&gt;140231657313168 -->\n<g class=\"edge\" id=\"edge7\">\n<title>140231700389392-&gt;140231657313168</title>\n<path d=\"M89.5,-219.4551C89.5,-211.3828 89.5,-201.6764 89.5,-192.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"93.0001,-192.5903 89.5,-182.5904 86.0001,-192.5904 93.0001,-192.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140231658611768 -->\n<g class=\"node\" id=\"node9\">\n<title>140231658611768</title>\n<polygon fill=\"none\" points=\"19,-73.5 19,-109.5 160,-109.5 160,-73.5 19,-73.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"89.5\" y=\"-87.8\">dropout_14: Dropout</text>\n</g>\n<!-- 140231657313168&#45;&gt;140231658611768 -->\n<g class=\"edge\" id=\"edge8\">\n<title>140231657313168-&gt;140231658611768</title>\n<path d=\"M89.5,-146.4551C89.5,-138.3828 89.5,-128.6764 89.5,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"93.0001,-119.5903 89.5,-109.5904 86.0001,-119.5904 93.0001,-119.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140231658635616 -->\n<g class=\"node\" id=\"node10\">\n<title>140231658635616</title>\n<polygon fill=\"none\" points=\"32.5,-.5 32.5,-36.5 146.5,-36.5 146.5,-.5 32.5,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"89.5\" y=\"-14.8\">dense_65: Dense</text>\n</g>\n<!-- 140231658611768&#45;&gt;140231658635616 -->\n<g class=\"edge\" id=\"edge9\">\n<title>140231658611768-&gt;140231658635616</title>\n<path d=\"M89.5,-73.4551C89.5,-65.3828 89.5,-55.6764 89.5,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"93.0001,-46.5903 89.5,-36.5904 86.0001,-46.5904 93.0001,-46.5903\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 227
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuPl3QoHgVCC",
        "outputId": "55cf24d3-2752-4b9c-d3f6-780a57c6e88b"
      },
      "source": [
        "# Train the model\r\n",
        "model1.fit(X_train,y_train, epochs = 10, batch_size = 2**5, verbose = True, validation_data = (X_test,y_test))"
      ],
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "366/366 [==============================] - 9s 24ms/step - loss: 0.8843 - categorical_accuracy: 0.6127 - val_loss: 0.6192 - val_categorical_accuracy: 0.7551\n",
            "Epoch 2/10\n",
            "366/366 [==============================] - 9s 24ms/step - loss: 0.6516 - categorical_accuracy: 0.7330 - val_loss: 0.5732 - val_categorical_accuracy: 0.7684\n",
            "Epoch 3/10\n",
            "366/366 [==============================] - 9s 24ms/step - loss: 0.5637 - categorical_accuracy: 0.7778 - val_loss: 0.5632 - val_categorical_accuracy: 0.7749\n",
            "Epoch 4/10\n",
            "366/366 [==============================] - 9s 24ms/step - loss: 0.4944 - categorical_accuracy: 0.8070 - val_loss: 0.5771 - val_categorical_accuracy: 0.7790\n",
            "Epoch 5/10\n",
            "366/366 [==============================] - 9s 24ms/step - loss: 0.4317 - categorical_accuracy: 0.8295 - val_loss: 0.5988 - val_categorical_accuracy: 0.7814\n",
            "Epoch 6/10\n",
            "366/366 [==============================] - 9s 24ms/step - loss: 0.3902 - categorical_accuracy: 0.8509 - val_loss: 0.6455 - val_categorical_accuracy: 0.7698\n",
            "Epoch 7/10\n",
            "366/366 [==============================] - 9s 24ms/step - loss: 0.3415 - categorical_accuracy: 0.8751 - val_loss: 0.7311 - val_categorical_accuracy: 0.7698\n",
            "Epoch 8/10\n",
            "366/366 [==============================] - 9s 24ms/step - loss: 0.3034 - categorical_accuracy: 0.8880 - val_loss: 0.8333 - val_categorical_accuracy: 0.7664\n",
            "Epoch 9/10\n",
            "366/366 [==============================] - 9s 24ms/step - loss: 0.2569 - categorical_accuracy: 0.9051 - val_loss: 0.8754 - val_categorical_accuracy: 0.7609\n",
            "Epoch 10/10\n",
            "366/366 [==============================] - 9s 24ms/step - loss: 0.2495 - categorical_accuracy: 0.9083 - val_loss: 0.9464 - val_categorical_accuracy: 0.7558\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8a46ee7588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 228
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZML5P-XkAc5",
        "outputId": "06bd64d7-5c7e-422c-cd1c-cfd6ea28d122"
      },
      "source": [
        "# Save model\r\n",
        "model1.save('Word2Vec_10epochs_NN')"
      ],
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: Word2Vec_10epochs_NN/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: Word2Vec_10epochs_NN/assets\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}