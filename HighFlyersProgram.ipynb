{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/obeabi/AirlineSentiment/blob/main/HighFlyersProgram.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Klw2WIf4amxd",
        "outputId": "4eed87f3-36c2-438c-90a1-4753fca49b70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.12/dist-packages (1.2.0)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (3.0.0)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2.2.6)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2.32.4)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.12/dist-packages (from yfinance) (0.0.12)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (4.5.1)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2025.2)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2.4.7)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.12/dist-packages (from yfinance) (3.19.0)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.12/dist-packages (from yfinance) (4.13.5)\n",
            "Requirement already satisfied: curl_cffi<0.14,>=0.7 in /usr/local/lib/python3.12/dist-packages (from yfinance) (0.13.0)\n",
            "Requirement already satisfied: protobuf>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (5.29.6)\n",
            "Requirement already satisfied: websockets>=13.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (15.0.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.8.3)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (4.15.0)\n",
            "Requirement already satisfied: cffi>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from curl_cffi<0.14,>=0.7->yfinance) (2.0.0)\n",
            "Requirement already satisfied: certifi>=2024.2.2 in /usr/local/lib/python3.12/dist-packages (from curl_cffi<0.14,>=0.7->yfinance) (2026.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31->yfinance) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31->yfinance) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31->yfinance) (2.5.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12.0->curl_cffi<0.14,>=0.7->yfinance) (3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.17.0)\n",
            "Requirement already satisfied: pandas_ta in /usr/local/lib/python3.12/dist-packages (0.4.71b0)\n",
            "Requirement already satisfied: numba==0.61.2 in /usr/local/lib/python3.12/dist-packages (from pandas_ta) (0.61.2)\n",
            "Requirement already satisfied: numpy>=2.2.6 in /usr/local/lib/python3.12/dist-packages (from pandas_ta) (2.2.6)\n",
            "Requirement already satisfied: pandas>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from pandas_ta) (3.0.0)\n",
            "Requirement already satisfied: tqdm>=4.67.1 in /usr/local/lib/python3.12/dist-packages (from pandas_ta) (4.67.3)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba==0.61.2->pandas_ta) (0.44.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.3.2->pandas_ta) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=2.3.2->pandas_ta) (1.17.0)\n",
            "Requirement already satisfied: ta in /usr/local/lib/python3.12/dist-packages (0.11.0)\n",
            "Requirement already satisfied: pandas_ta in /usr/local/lib/python3.12/dist-packages (0.4.71b0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from ta) (2.2.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from ta) (3.0.0)\n",
            "Requirement already satisfied: numba==0.61.2 in /usr/local/lib/python3.12/dist-packages (from pandas_ta) (0.61.2)\n",
            "Requirement already satisfied: tqdm>=4.67.1 in /usr/local/lib/python3.12/dist-packages (from pandas_ta) (4.67.3)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba==0.61.2->pandas_ta) (0.44.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->ta) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->ta) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade yfinance\n",
        "!pip install  --upgrade pandas_ta\n",
        "!pip install ta pandas_ta\n",
        "!pip install scipy==1.16.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "feLesZUfcB8j"
      },
      "outputs": [],
      "source": [
        "import yfinance as yf\n",
        "print(yf.__version__)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import time\n",
        "import ta\n",
        "import random\n",
        "import requests\n",
        "from datetime import datetime, timedelta\n",
        "from scipy.stats import linregress\n",
        "from transformers import pipeline\n",
        "# ensure reproducibility\n",
        "random.seed(42)\n",
        "print(\"Libraries Installed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdozdC6UKIN9"
      },
      "outputs": [],
      "source": [
        "today = datetime.today()\n",
        "start_of_year = today.replace(month=1, day=1)\n",
        "\n",
        "# First day of this month\n",
        "first_day_month = today.replace(day=1)\n",
        "\n",
        "# First day of this week (Monday as weekday 0)\n",
        "first_day_week = today - timedelta(days=today.weekday())\n",
        "print(\"First day of year:\", start_of_year)\n",
        "\n",
        "print(\"\\nFirst day of this month:\", first_day_month)\n",
        "print(\"\\nFirst day of this week:\", first_day_week)\n",
        "\n",
        "def most_recent_quarter_start(today=None):\n",
        "    if today is None:\n",
        "        today = pd.Timestamp.today().normalize()\n",
        "    year = today.year\n",
        "    month = today.month\n",
        "\n",
        "    # Determine quarter start months: Jan, Apr, Jul, Oct\n",
        "    if month >= 10:\n",
        "        q_start = pd.Timestamp(year, 10, 1)\n",
        "    elif month >= 7:\n",
        "        q_start = pd.Timestamp(year, 7, 1)\n",
        "    elif month >= 4:\n",
        "        q_start = pd.Timestamp(year, 4, 1)\n",
        "    else:\n",
        "        q_start = pd.Timestamp(year, 1, 1)\n",
        "\n",
        "    return q_start\n",
        "\n",
        "# Example usage\n",
        "print(\"Today:\", pd.Timestamp.today().normalize())\n",
        "print(\"Most recent quarter start:\", most_recent_quarter_start())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QpUSliTGKRG7"
      },
      "outputs": [],
      "source": [
        "# List of ETFs to analyze\n",
        "#df_o = pd.read_csv('stock_list.csv')\n",
        "\n",
        "df_raw = pd.read_csv('small_list.csv')\n",
        "df_raw = df_raw[df_raw['Type'].isin(['Stock'])]\n",
        "recent_quarter = most_recent_quarter_start()\n",
        "etfs = df_raw['Asset'].to_list()\n",
        "print(etfs)\n",
        "\n",
        "print(len(etfs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhwDkP7-KfX0"
      },
      "source": [
        "## Filter for liquidity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nyRknoZsKdPt"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Filter ETFs or stocks for liquidity\n",
        "def filter_by_liquidity(etf_df, ticker_col=\"Asset\", min_dollar_vol=10e6, lookback_days=30):\n",
        "    liquid_etfs = []\n",
        "\n",
        "    for ticker in etf_df[ticker_col]:\n",
        "        try:\n",
        "            # Fetch daily historical data\n",
        "            data = yf.download(ticker, period=f\"{lookback_days*2}d\", interval=\"1d\", auto_adjust=True)\n",
        "\n",
        "            if data.empty:\n",
        "                continue\n",
        "\n",
        "            # Calculate dollar volume (Close × Volume)\n",
        "            data[\"dollar_volume\"] = data[\"Close\"] * data[\"Volume\"]\n",
        "\n",
        "            # Calculate rolling average over lookback_days\n",
        "            avg_dollar_volume = data[\"dollar_volume\"].rolling(window=lookback_days).mean().iloc[-1]\n",
        "\n",
        "            # Check liquidity condition\n",
        "            if avg_dollar_volume >= min_dollar_vol:\n",
        "                liquid_etfs.append(ticker)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error fetching {ticker}: {e}\")\n",
        "\n",
        "    # Return filtered DataFrame\n",
        "    return etf_df[etf_df[ticker_col].isin(liquid_etfs)]\n",
        "\n",
        "# Example usage\n",
        "df = pd.DataFrame({\"Assets\": etfs})\n",
        "liquid_df = filter_by_liquidity(df, ticker_col=\"Assets\")\n",
        "df_o = df_raw[df_raw['Asset'].isin(liquid_df['Assets'])]\n",
        "etfs = df_o['Asset'].to_list()\n",
        "print(\"\")\n",
        "print(etfs)\n",
        "print(len(etfs))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "327zottzJ3qp"
      },
      "source": [
        "# Classify Sector Stages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UacD-c4QJ5Bq"
      },
      "outputs": [],
      "source": [
        "\n",
        "def weinstein_stage(df, sma_window=30,smaSlope_window=10):\n",
        "    \"\"\"Determine Weinstein stage using 30-week SMA and its slope.\"\"\"\n",
        "     # Handle MultiIndex columns\n",
        "    if isinstance(df.columns, pd.MultiIndex):\n",
        "        df.columns = df.columns.get_level_values(0)\n",
        "    df[\"SMA\"] = df[\"Close\"].rolling(window=sma_window).mean()\n",
        "    df[\"10_SMA\"] = df[\"Close\"].rolling(window=10).mean()\n",
        "\n",
        "    # Compute linear regression slope on last N SMA points\n",
        "    if len(df.dropna()) < sma_window:\n",
        "        return None  # not enough data\n",
        "\n",
        "    slope, _, _, _, _ = linregress(range(smaSlope_window), df[\"SMA\"].tail(smaSlope_window))\n",
        "    #slope_short, _, _, _, _ = linregress(range(smaSlope_window), df[\"10_SMA\"].tail(smaSlope_window))\n",
        "\n",
        "    latest_price = df[\"Close\"].iloc[-1]\n",
        "    latest_sma   = df[\"SMA\"].iloc[-1]\n",
        "    latest_10sma = df[\"10_SMA\"].iloc[-1]\n",
        "\n",
        "    # Determine stage\n",
        "    if (latest_price > latest_sma) and (slope > 0) and (latest_price > latest_10sma) and (latest_10sma > latest_sma):\n",
        "        stage = \"Stage 2 (Advancing)\"\n",
        "    elif latest_price < latest_sma and slope < 0:\n",
        "        stage = \"Stage 4 (Declining)\"\n",
        "    elif np.abs(slope) <= 0.001:\n",
        "        stage = \"Stage 1 (Basing)\"\n",
        "    else:\n",
        "        stage = \"Stage 3 (Topping)\"\n",
        "\n",
        "    return stage, slope, latest_price, latest_sma, latest_10sma\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBSwTrYnlW7y"
      },
      "outputs": [],
      "source": [
        "\n",
        "results = []\n",
        "for etf in etfs:\n",
        "    df = yf.download(etf, period=\"3y\", interval=\"1wk\", auto_adjust=True)\n",
        "    stage_info = weinstein_stage(df)\n",
        "    if stage_info:\n",
        "        stage, slope, price, sma,sma_10 = stage_info\n",
        "        results.append({\n",
        "            \"ETF\": etf,\n",
        "            \"Stage\": stage,\n",
        "            \"SMA_Slope\": slope,\n",
        "            \"Latest_Price\": price,\n",
        "            \"30W_SMA\": sma,\n",
        "            \"10W_SMA\": sma_10\n",
        "        })\n",
        "\n",
        "stages_df = pd.DataFrame(results).sort_values(by=\"SMA_Slope\", ascending=False)\n",
        "#print(len(stages_df))\n",
        "stages_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FcC-w9agLBQf"
      },
      "outputs": [],
      "source": [
        "advancing_stocks= stages_df[stages_df[\"Stage\"] .isin([\"Stage 2 (Advancing)\"]) ]\n",
        "advancing_stocks.reset_index(drop=True, inplace=True)\n",
        "advancing_stocks.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9IKx7dj9cT5K"
      },
      "outputs": [],
      "source": [
        "# List of ETFs to analyze\n",
        "df_o = df_o[df_o['Asset'].isin(advancing_stocks['ETF'])]\n",
        "#df_raw = pd.read_csv('etf_list.csv')\n",
        "#df_raw = df_raw[df_raw['Type'].isin(['ETF','Stock'])]\n",
        "#recent_quarter = most_recent_quarter_start()\n",
        "etfs = df_o['Asset'].to_list()\n",
        "print(etfs)\n",
        "\n",
        "print(len(etfs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8jLJmG-8m2OH"
      },
      "outputs": [],
      "source": [
        "\n",
        "def macdv(prices, fast=12, slow=26, signal=9, atr_window=10, thresholds=(50, 150)):\n",
        "    \"\"\"\n",
        "    Compute MACD-V (volatility normalized MACD).\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    prices : pd.Series\n",
        "        Price series (e.g. closing prices).\n",
        "    fast : int\n",
        "        Fast EMA period.\n",
        "    slow : int\n",
        "        Slow EMA period.\n",
        "    signal : int\n",
        "        Signal EMA period for MACD line.\n",
        "    atr_window : int\n",
        "        ATR lookback window.\n",
        "    thresholds : tuple\n",
        "        (lower, upper) thresholds for neutral/ranging and extreme momentum zones.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    pd.DataFrame with columns:\n",
        "        - MACDV : MACD-V value\n",
        "        - Signal : EMA of MACDV\n",
        "        - Histogram : MACDV - Signal\n",
        "        - EntryFlag : True when momentum is strong enough, False otherwise\n",
        "    \"\"\"\n",
        "    # --- Step 1: EMAs for MACD ---\n",
        "    ema_fast = prices.ewm(span=fast, adjust=False).mean()\n",
        "    ema_slow = prices.ewm(span=slow, adjust=False).mean()\n",
        "    macd_raw = ema_fast - ema_slow\n",
        "\n",
        "    # --- Step 2: ATR for normalization ---\n",
        "    high = prices.shift(1) * (1 + 0.01)   # synthetic highs/lows if OHLC not available\n",
        "    low = prices.shift(1) * (1 - 0.01)\n",
        "    close = prices\n",
        "    tr1 = high - low\n",
        "    tr2 = (high - close.shift(1)).abs()\n",
        "    tr3 = (low - close.shift(1)).abs()\n",
        "    tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)\n",
        "    atr = tr.rolling(atr_window).mean()\n",
        "\n",
        "    # --- Step 3: Normalize MACD by ATR ---\n",
        "    macdv = (macd_raw / atr) * 100\n",
        "\n",
        "    # --- Step 4: Signal line and histogram ---\n",
        "    signal_line = macdv.ewm(span=signal, adjust=False).mean()\n",
        "    histogram = macdv - signal_line\n",
        "\n",
        "    # --- Step 5: Entry conditions ---\n",
        "    lower, upper = thresholds\n",
        "    entry_flag = ((macdv.abs() > lower) & (macdv.abs() < upper)) | (macdv.abs() > upper)\n",
        "\n",
        "    df = pd.DataFrame({\n",
        "        \"MACDV\": macdv,\n",
        "        \"Signal\": signal_line,\n",
        "        \"Histogram\": histogram,\n",
        "        \"EntryFlag\": entry_flag\n",
        "    })\n",
        "    curr = df.iloc[-1]\n",
        "\n",
        "    return curr.EntryFlag\n",
        "\n",
        "def money_flow_signals(df, period=10):\n",
        "    \"\"\"\n",
        "    Calculate Money Flow Index (MFI) and generate signals:\n",
        "    - Positive money flow (TP > TP_prev)\n",
        "    - Divergence (Price vs MFI mismatch)\n",
        "\n",
        "    Parameters:\n",
        "        df (pd.DataFrame): DataFrame with columns [\"High\", \"Low\", \"Close\", \"Volume\"]\n",
        "        period (int): Lookback period for MFI (default=10)\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame with added columns: [\"TypicalPrice\", \"MFI\", \"PositiveFlow\", \"Divergence\"]\n",
        "    \"\"\"\n",
        "\n",
        "    df = df.copy()\n",
        "\n",
        "    # Step 1: Typical Price\n",
        "    df[\"TypicalPrice\"] = (df[\"High\"] + df[\"Low\"] + df[\"Close\"]) / 3\n",
        "\n",
        "    # Step 2: Raw Money Flow\n",
        "    df[\"RawMoneyFlow\"] = df[\"TypicalPrice\"] * df[\"Volume\"]\n",
        "\n",
        "    # Step 3: Positive & Negative Flow\n",
        "    df[\"PositiveFlow\"] = np.where(df[\"TypicalPrice\"] > df[\"TypicalPrice\"].shift(1), df[\"RawMoneyFlow\"], 0.0)\n",
        "    df[\"NegativeFlow\"] = np.where(df[\"TypicalPrice\"] < df[\"TypicalPrice\"].shift(1), df[\"RawMoneyFlow\"], 0.0)\n",
        "\n",
        "    # Step 4: Money Flow Ratio & MFI\n",
        "    pos_flow = df[\"PositiveFlow\"].rolling(period).sum()\n",
        "    neg_flow = df[\"NegativeFlow\"].rolling(period).sum()\n",
        "    money_flow_ratio = pos_flow / neg_flow.replace(0, np.nan)\n",
        "    df[\"MFI\"] = 100 - (100 / (1 + money_flow_ratio))\n",
        "\n",
        "    # Step 5: Positive Money Flow Signal\n",
        "    df[\"PositiveFlowSignal\"] = df[\"TypicalPrice\"] > df[\"TypicalPrice\"].shift(1)\n",
        "\n",
        "    # Step 6: Divergence Detection\n",
        "    df[\"PriceHigh\"] = df[\"Close\"].rolling(period).max()\n",
        "    df[\"PriceLow\"] = df[\"Close\"].rolling(period).min()\n",
        "    df[\"MFIHigh\"] = df[\"MFI\"].rolling(period).max()\n",
        "    df[\"MFILow\"] = df[\"MFI\"].rolling(period).min()\n",
        "\n",
        "    def divergence(row):\n",
        "        if np.isnan(row[\"MFI\"]):\n",
        "            return None\n",
        "        # Price makes higher high, but MFI does not\n",
        "        if row[\"Close\"] >= row[\"PriceHigh\"] and row[\"MFI\"] < row[\"MFIHigh\"]:\n",
        "            return \"Bearish Divergence ⚠️\"\n",
        "        # Price makes lower low, but MFI does not\n",
        "        elif row[\"Close\"] <= row[\"PriceLow\"] and row[\"MFI\"] > row[\"MFILow\"]:\n",
        "            return \"Bullish Divergence ✅\"\n",
        "        else:\n",
        "            return \"No Divergence\"\n",
        "\n",
        "    df[\"Divergence\"] = df.apply(divergence, axis=1)\n",
        "    df['Entry_signal']= (df[\"MFI\"] > 50) & (df[\"Divergence\"] == \"No Divergence\")\n",
        "    curr = df.iloc[-1]\n",
        "\n",
        "    return curr.Entry_signal\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UjGkzJcGcy17"
      },
      "outputs": [],
      "source": [
        "# Function to fetch historical weekly data\n",
        "def rolling_regression_slope(series, window=10):\n",
        "    \"\"\"Rolling linear regression slope (price units per bar).\"\"\"\n",
        "    def calc_slope(y):\n",
        "        if len(y) < 2:\n",
        "            return np.nan\n",
        "        x = np.arange(len(y))\n",
        "        slope, _, _, _, _ = linregress(x, y)\n",
        "        return slope\n",
        "    return series.rolling(window).apply(calc_slope, raw=False)\n",
        "\n",
        "def anchored_vwap(ticker: str, lookback_weeks: int = 5):\n",
        "    \"\"\"\n",
        "    Calculate the Anchored VWAP from the most recent high within the past `lookback_weeks`\n",
        "    and create a 'Signal' column that gives 'Buy' when Close > Anchored_VWAP, else 'No-Buy'.\n",
        "\n",
        "    Args:\n",
        "        ticker (str): Stock ticker symbol\n",
        "        lookback_weeks (int): Number of weeks to look back for the highest price\n",
        "\n",
        "    Returns:\n",
        "        pandas.DataFrame: DataFrame with OHLC, Volume, Anchored_VWAP, and Signal columns\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # --- Fetch 6 months of daily data to cover the lookback window\n",
        "        data = yf.download(ticker, period=\"6mo\", interval=\"1d\", progress=False,auto_adjust=True)\n",
        "        if isinstance(data.columns, pd.MultiIndex):\n",
        "          data.columns = data.columns.get_level_values(0)  # keep only first level\n",
        "\n",
        "        if data.empty:\n",
        "            raise ValueError(f\"No data retrieved for ticker {ticker}\")\n",
        "\n",
        "        data.dropna(inplace=True)\n",
        "        data.index = pd.to_datetime(data.index)\n",
        "\n",
        "        # --- Ensure we have enough data for the lookback period\n",
        "        min_days_required = lookback_weeks * 10  # ~5 trading days per week\n",
        "        if len(data) < min_days_required:\n",
        "            raise ValueError(f\"Insufficient data: {len(data)} days available, {min_days_required} required\")\n",
        "\n",
        "        # --- Find the most recent high within the past lookback_weeks\n",
        "        recent_period = data.tail(min_days_required)\n",
        "        anchor_date = recent_period['High'].idxmax()\n",
        "\n",
        "        # --- Verify anchor_date is a valid Timestamp\n",
        "        if not isinstance(anchor_date, pd.Timestamp):\n",
        "            raise ValueError(f\"Invalid anchor_date: {anchor_date}. Expected a Timestamp.\")\n",
        "\n",
        "        anchor_price = recent_period.loc[anchor_date, 'High']\n",
        "\n",
        "        # --- Use .date() safely since we confirmed anchor_date is a Timestamp\n",
        "        print(f\"\\nAnchored VWAP for {ticker} starting from {anchor_date.date()} (recent high = {anchor_price:.2f})\")\n",
        "\n",
        "        # --- Slice data from the anchor date onwards\n",
        "        anchor_data = data.loc[anchor_date:]\n",
        "\n",
        "        # --- Compute VWAP starting from the anchor date\n",
        "        # Use typical price ((H+L+C)/3) for more accurate VWAP\n",
        "        typical_price = (anchor_data['High'] + anchor_data['Low'] + anchor_data['Close']) / 3\n",
        "        q = anchor_data['Volume']\n",
        "        pv = (typical_price * q).cumsum()\n",
        "        v = q.cumsum()\n",
        "\n",
        "        # --- Avoid division by zero\n",
        "        avwap = pv / v.where(v != 0, np.nan)\n",
        "\n",
        "        # --- Add Anchored VWAP to the full dataset\n",
        "        data['Anchored_VWAP'] = np.nan  # Initialize with NaN\n",
        "        data.loc[anchor_date:, 'Anchored_VWAP'] = avwap\n",
        "        # --- Add swing high information to the DataFrame\n",
        "        data['Swing_High_Price'] = anchor_price\n",
        "        data['Swing_High_Date'] = anchor_date\n",
        "\n",
        "        # --- Create Buy/No-Buy Signal\n",
        "        # Only apply signal where Anchored_VWAP is not NaN\n",
        "        data['Signal'] = np.where(\n",
        "            (data['Close'] > data['Anchored_VWAP']) & (data['Anchored_VWAP'].notna()),\n",
        "            True,\n",
        "            False\n",
        "        )\n",
        "\n",
        "        return data[['Anchored_VWAP', 'Signal','Swing_High_Price']]\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {ticker}: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def anchored_vwap_old(ticker, anchor_date):\n",
        "    \"\"\"\n",
        "    Calculate Anchored VWAP starting from a given anchor_date.\n",
        "    Works with both single-level and multi-level columns (e.g. yfinance output).\n",
        "    \"\"\"\n",
        "    # --- Step 1: Flatten columns if multi-index ---\n",
        "    df = yf.download(ticker, period=\"1y\", interval=\"1d\",auto_adjust=True)\n",
        "    if isinstance(df.columns, pd.MultiIndex):\n",
        "        df.columns = df.columns.get_level_values(0)  # keep only first level\n",
        "\n",
        "    # --- Step 2: Ensure required columns exist ---\n",
        "    required_cols = [\"High\", \"Low\", \"Close\", \"Volume\"]\n",
        "    for col in required_cols:\n",
        "        if col not in df.columns:\n",
        "            raise ValueError(f\"Missing required column: {col}\")\n",
        "\n",
        "    # --- Step 3: Subset from anchor_date ---\n",
        "    df_anchor = df.loc[df.index >= pd.to_datetime(anchor_date)].copy()\n",
        "    if df_anchor.empty:\n",
        "        raise ValueError(f\"No data found on/after {anchor_date}\")\n",
        "\n",
        "    # --- Step 4: Compute typical price ---\n",
        "    df_anchor[\"typical_price\"] = (df_anchor[\"High\"] + df_anchor[\"Low\"] + df_anchor[\"Close\"]) / 3.0\n",
        "\n",
        "    # --- Step 5: Cumulative PV and VWAP ---\n",
        "    df_anchor[\"cum_pv\"] = (df_anchor[\"typical_price\"].astype(float) * df_anchor[\"Volume\"].astype(float)).cumsum()\n",
        "    df_anchor[\"cum_vol\"] = df_anchor[\"Volume\"].astype(float).cumsum()\n",
        "    df_anchor[\"anchored_vwap\"] = df_anchor[\"cum_pv\"] / df_anchor[\"cum_vol\"]\n",
        "\n",
        "    return df_anchor[[\"anchored_vwap\"]]\n",
        "\n",
        "def get_monthly_data(ticker):\n",
        "  try:\n",
        "      df = yf.download(ticker, period=\"10y\", interval=\"1mo\",auto_adjust=True)\n",
        "\n",
        "      #if isinstance(df.columns, pd.MultiIndex):\n",
        "        #df.columns = df.columns.get_level_values(0)  # keep only first level\n",
        "      # Compute MACD using ta\n",
        "      df['10_month_SMA'] = df['Close'].rolling(window=10).mean()\n",
        "      df['slope_raw'] = rolling_regression_slope(df['10_month_SMA'], window=5)\n",
        "      # Calculate MACD and Signal Line\n",
        "      df['12_EMA'] = df['Close'].ewm(span=12, adjust=False).mean()\n",
        "      df['26_EMA'] = df['Close'].ewm(span=26, adjust=False).mean()\n",
        "      # Compute MACD Line\n",
        "      df['MACD_Line'] = df['12_EMA'] - df['26_EMA']\n",
        "      # Compute Signal Line (9-day EMA of MACD Line)\n",
        "      df['Signal_Line'] = df['MACD_Line'].ewm(span=9, adjust=False).mean()\n",
        "      df['MACD_Hist'] = df['MACD_Line'] - df['Signal_Line']\n",
        "      #df['AvgVolume'] = df[\"Volume\"].rolling(window=10).mean()\n",
        "      df['RVOL'] = df['Volume'] / df['Volume'].rolling(window=10).mean()\n",
        "      df['RVOL_Slope'] = df['RVOL'].diff()\n",
        "      # Calculate ADX, +DMI and -DMI\n",
        "      high = df['High']\n",
        "      low = df['Low']\n",
        "      close = df['Close']\n",
        "      # Calculate directional movements\n",
        "      up_move = high.diff()\n",
        "      down_move = -low.diff()\n",
        "      plus_dm = np.where((up_move > down_move) & (up_move > 0), up_move, 0.0)\n",
        "      minus_dm = np.where((down_move > up_move) & (down_move > 0), down_move, 0.0)\n",
        "      # Calculate True Range (TR)\n",
        "      tr1 = high - low\n",
        "      tr2 = (high - close.shift()).abs()\n",
        "      tr3 = (low - close.shift()).abs()\n",
        "      tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)\n",
        "      # Smooth TR, +DM, and -DM using Wilder’s smoothing\n",
        "      atr = tr.rolling(window=14).sum()\n",
        "      plus_dm_series = pd.Series(plus_dm.ravel(), index=df.index).astype(float)\n",
        "      minus_dm_series = pd.Series(minus_dm.ravel(), index=df.index).astype(float)\n",
        "      plus_dm_smoothed = plus_dm_series.rolling(window=14).sum()\n",
        "      minus_dm_smoothed = minus_dm_series.rolling(window=14).sum()\n",
        "      # Directional Indicators\n",
        "      plus_di = 100 * (plus_dm_smoothed / atr)\n",
        "      minus_di = 100 * (minus_dm_smoothed / atr)\n",
        "      # DX and ADX\n",
        "      dx = 100 * (np.abs(plus_di - minus_di) / (plus_di + minus_di))\n",
        "      adx = dx.rolling(window=14).mean()\n",
        "      # Add results to original DataFrame\n",
        "      df['+DI'] = plus_di\n",
        "      df['-DI'] = minus_di\n",
        "      df['ADX'] = adx\n",
        "      df['di_flag'] = df['+DI'] > df['-DI']\n",
        "      df['di_flag'] = df['di_flag'].astype(int)\n",
        "      df['adx_indicator'] = np.where(df['ADX'] > 10, 1, 0)\n",
        "      df['adx_signal'] = df['adx_indicator'] * df['di_flag']\n",
        "\n",
        "      return df\n",
        "  except Exception as e:\n",
        "      print(\"There is an error getting monthly data\", e)\n",
        "\n",
        "def get_weekly_data(ticker):\n",
        "  try:\n",
        "      df = yf.download(ticker, period=\"10y\", interval=\"1wk\",auto_adjust=True)\n",
        "      #if isinstance(df.columns, pd.MultiIndex):\n",
        "        #df.columns = df.columns.get_level_values(0)  # keep only first level\n",
        "      df['10_week_SMA'] = df['Close'].rolling(window=10).mean()\n",
        "      df['30_week_SMA'] = df['Close'].rolling(window=30).mean()\n",
        "      df['slope_raw'] = rolling_regression_slope(df['30_week_SMA'], window=10)\n",
        "      df['slope_pct_per_week'] = df['slope_raw'] / df['30_week_SMA']          # fractional change per week\n",
        "      df['SMA_Slope'] = df['slope_pct_per_week'] * 52 * 100       # % per year\n",
        "      # Optional: also keep a simple angle if you still want it\n",
        "      df['slope_angle_deg'] = np.degrees(np.arctan(df['slope_pct_per_week'] * 52))\n",
        "      df['10_EMA'] = df['Close'].ewm(span=10, adjust=False).mean()\n",
        "      df['20_EMA'] = df['Close'].ewm(span=20, adjust=False).mean()\n",
        "      df['ATR'] = compute_atr(df, 14)\n",
        "      df['OBV'] = compute_obv(df)\n",
        "      obv_slope, _, _, _, _ = linregress(range(30), df[\"OBV\"].tail(30))\n",
        "      df['OBV_Slope'] = obv_slope\n",
        "      df['30_week_avg_volume'] = df['Volume'].rolling(window=30).mean()\n",
        "      # Calculate MACD and Signal Line\n",
        "      df['12_EMA'] = df['Close'].ewm(span=12, adjust=False).mean()\n",
        "      df['21_EMA'] = df['Close'].ewm(span=21, adjust=False).mean()\n",
        "      df['26_EMA'] = df['Close'].ewm(span=26, adjust=False).mean()\n",
        "      # Compute MACD Line\n",
        "      df['MACD_Line'] = df['12_EMA'] - df['26_EMA']\n",
        "      # Compute Signal Line (9-day EMA of MACD Line)\n",
        "      df['Signal_Line'] = df['MACD_Line'].ewm(span=9, adjust=False).mean()\n",
        "      df['MACD_Hist'] = df['MACD_Line'] - df['Signal_Line']\n",
        "      # Compute raw EFI\n",
        "      df['EFI'] = (df['Close'].diff()) * df['Volume']\n",
        "      # Compute EMA of EFI\n",
        "      df['EFI_EMA'] = df['EFI'].ewm(span=13, adjust=False).mean()\n",
        "      # Determine if EFI_EMA is rising or falling\n",
        "      df['EFI_EMA_Trend'] = df['EFI_EMA'].diff().apply(lambda x: 'Rising' if x > 0 else 'Falling')\n",
        "      # Calculate ADX, +DMI and -DMI\n",
        "      high = df['High']\n",
        "      low = df['Low']\n",
        "      close = df['Close']\n",
        "      # Calculate directional movements\n",
        "      up_move = high.diff()\n",
        "      down_move = -low.diff()\n",
        "      plus_dm = np.where((up_move > down_move) & (up_move > 0), up_move, 0.0)\n",
        "      minus_dm = np.where((down_move > up_move) & (down_move > 0), down_move, 0.0)\n",
        "      # Calculate True Range (TR)\n",
        "      tr1 = high - low\n",
        "      tr2 = (high - close.shift()).abs()\n",
        "      tr3 = (low - close.shift()).abs()\n",
        "      tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)\n",
        "      # Smooth TR, +DM, and -DM using Wilder’s smoothing\n",
        "      atr = tr.rolling(window=14).sum()\n",
        "      plus_dm_series = pd.Series(plus_dm.ravel(), index=df.index).astype(float)\n",
        "      minus_dm_series = pd.Series(minus_dm.ravel(), index=df.index).astype(float)\n",
        "      plus_dm_smoothed = plus_dm_series.rolling(window=14).sum()\n",
        "      minus_dm_smoothed = minus_dm_series.rolling(window=14).sum()\n",
        "      # Directional Indicators\n",
        "      plus_di = 100 * (plus_dm_smoothed / atr)\n",
        "      minus_di = 100 * (minus_dm_smoothed / atr)\n",
        "      # DX and ADX\n",
        "      dx = 100 * (np.abs(plus_di - minus_di) / (plus_di + minus_di))\n",
        "      adx = dx.rolling(window=14).mean()\n",
        "      # Add results to original DataFrame\n",
        "      df['+DI'] = plus_di\n",
        "      df['-DI'] = minus_di\n",
        "      df['ADX'] = adx\n",
        "      df['di_flag'] = df['+DI'] > df['-DI']\n",
        "      df['di_flag'] = df['di_flag'].astype(int)\n",
        "      df['adx_indicator'] = np.where(df['ADX'] > 10, 1, 0)\n",
        "      df['adx_signal'] = df['adx_indicator'] * df['di_flag']\n",
        "\n",
        "      # --- Overhead Resistance Filter ---\n",
        "      recent_52_weeks = df[-52:]\n",
        "      max_close_52w = recent_52_weeks['Close'].max().iloc[0]\n",
        "      max_price = df['Close'].max().iloc[0]\n",
        "      last_close = df['Close'].iloc[-1].iloc[0]\n",
        "      # Filter condition: Close is within 15% of 52-week high\n",
        "      df['No_Overhead_Resistance'] = last_close > (max_close_52w*0.80)\n",
        "      # --- Above 52 weeks High ---\n",
        "      df['above_52w_high'] = last_close > max_close_52w\n",
        "      df['below_52w_high'] = last_close < max_close_52w\n",
        "\n",
        "      return df\n",
        "  except Exception as e:\n",
        "      print(\"There is an error getting weekly data\", e)\n",
        "\n",
        "def is_macd_bullish(df):\n",
        "    \"\"\"\n",
        "    Determines if there is a bullish signal on the MACD indicator.\n",
        "    A bullish signal occurs when the MACD line is above the signal line.\n",
        "\n",
        "    Parameters:\n",
        "    - df: dataframe. Must have columns 'MACD_Line' and 'Signal_Line'.\n",
        "    Returns:\n",
        "    - bool: True if a bullish signal is detected, otherwise False.\n",
        "    \"\"\"\n",
        "    try:\n",
        "      if df.empty:\n",
        "        return False\n",
        "      # Calculate MACD histogram if not already present\n",
        "\n",
        "      curr = df.iloc[-3:]\n",
        "      macd_crossover = curr['MACD_Line'].iloc[-1] > curr['Signal_Line'].iloc[-1]\n",
        "      hist_increasing = (curr['MACD_Hist'].iloc[-1] > curr['MACD_Hist'].iloc[-2]) \\\n",
        "                         or (curr['MACD_Hist'].iloc[-2] > curr['MACD_Hist'].iloc[-3])\n",
        "\n",
        "      return macd_crossover\n",
        "              #and (hist_increasing or curr['MACD_Hist'].iloc[-1] > 0)\n",
        "    except Exception as e:\n",
        "      print(\"Something went wrong while computing the MACD\", e)\n",
        "\n",
        "def is_macd_bullish_hr(df):\n",
        "    \"\"\"\n",
        "    Determines if there is a bullish signal on the MACD indicator on hourly chart.\n",
        "    A bullish signal occurs when the MACD line is above the signal line.\n",
        "\n",
        "    Parameters:\n",
        "    - df: dataframe. Must have columns 'MACD_Line' and 'Signal_Line'.\n",
        "    Returns:\n",
        "    - bool: True if a bullish signal is detected, otherwise False.\n",
        "    \"\"\"\n",
        "    try:\n",
        "      if df.empty:\n",
        "        return False\n",
        "      # Calculate MACD histogram if not already present\n",
        "\n",
        "      curr = df.iloc[-3:]\n",
        "      macd_crossover = curr['MACD_Line'].iloc[-1] > curr['Signal_Line'].iloc[-1]\n",
        "\n",
        "      return macd_crossover\n",
        "             # and curr['MACD_Hist'].iloc[-1] > 0\n",
        "    except Exception as e:\n",
        "      print(\"Something went wrong while computing the MACD\", e)\n",
        "\n",
        "def is_macd_bullish_min(df):\n",
        "    \"\"\"\n",
        "    Determines if there is a bullish signal on the MACD indicator on 15 minute chart.\n",
        "    A bullish signal occurs when the MACD line is above the signal line.\n",
        "\n",
        "    Parameters:\n",
        "    - df: dataframe. Must have columns 'MACD_Line' and 'Signal_Line'.\n",
        "    Returns:\n",
        "    - bool: True if a bullish signal is detected, otherwise False.\n",
        "    \"\"\"\n",
        "    try:\n",
        "      if df.empty:\n",
        "        return False\n",
        "      # Calculate MACD histogram if not already present\n",
        "\n",
        "      curr = df.iloc[-3:]\n",
        "      macd_crossover = curr['MACD_Line'].iloc[-1] > curr['Signal_Line'].iloc[-1]\n",
        "\n",
        "      return macd_crossover\n",
        "    except Exception as e:\n",
        "      print(\"Something went wrong while computing the MACD\", e)\n",
        "\n",
        "def calculate_bbw(df, window=20):\n",
        "    \"\"\" Calculates Bollinger Bands Width\"\"\"\n",
        "    sma = df['Close'].rolling(window).mean()\n",
        "    std = df['Close'].rolling(window).std()\n",
        "    upper = sma + 2*std\n",
        "    lower = sma - 2*std\n",
        "    bbw = (upper - lower) / sma\n",
        "    return bbw\n",
        "\n",
        "def calculate_vwap(df):\n",
        "  \"\"\" Calculates vwap\"\"\"\n",
        "  try:\n",
        "    Typical_Price = (df['Close'].values + df['High'].values + df['Low'].values) / 3\n",
        "    TPV = Typical_Price * df['Volume'].values\n",
        "    vwap = TPV.cumsum() / df['Volume'].values.cumsum()\n",
        "    return vwap\n",
        "  except Exception as e:\n",
        "    print(\"Something went wrong while computing the VWAP:\", e)\n",
        "    return None\n",
        "\n",
        "# Function to compute RSI\n",
        "def compute_rsi(series, period=10):\n",
        "  try:\n",
        "    delta = series.diff()\n",
        "    gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()\n",
        "    loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()\n",
        "    rs = gain / loss\n",
        "    return 100 - (100 / (1 + rs))\n",
        "  except Exception as e:\n",
        "        print(\"Something went wrong while computing the RSI:\", e)\n",
        "        return None\n",
        "\n",
        "def calculate_ma(data, length=10, ma_type=\"WMA\"):\n",
        "    if ma_type == \"SMA\":\n",
        "        return data.rolling(window=length).mean()\n",
        "    elif ma_type == \"EMA\":\n",
        "        return data.ewm(span=length, adjust=False).mean()\n",
        "    elif ma_type == \"WMA\":\n",
        "        weights = np.arange(1, length+1)\n",
        "        return data.rolling(length).apply(lambda x: np.dot(x, weights)/weights.sum(), raw=True)\n",
        "    elif ma_type == \"VWMA\":\n",
        "        return ta.volume_weighted_average_price(data, length)\n",
        "\n",
        "def calculate_bollinger_bands(data, length=10, std_dev=2.0):\n",
        "    sma = data.rolling(window=length).mean()\n",
        "    std_dev = data.rolling(window=length).std()\n",
        "    upper_band = sma + (std_dev * std_dev)\n",
        "    lower_band = sma - (std_dev * std_dev)\n",
        "    return upper_band, lower_band\n",
        "\n",
        "# Function to compute ATR (Average True Range)\n",
        "def compute_atr(df, period=10):\n",
        "  try:\n",
        "    df['High-Low'] = df['High'] - df['Low']\n",
        "    df['High-Close'] = abs(df['High'] - df['Close'].shift(1))\n",
        "    df['Low-Close'] = abs(df['Low'] - df['Close'].shift(1))\n",
        "    df['TR'] = df[['High-Low', 'High-Close', 'Low-Close']].max(axis=1)\n",
        "    return df['TR'].rolling(window=period).mean()\n",
        "  except Exception as e:\n",
        "      print(\"Something went wrong whilecomputing the ATR\", e)\n",
        "\n",
        "\n",
        "# Function to compute On-Balance Volume (OBV)\n",
        "def compute_obv(df):\n",
        "  try:\n",
        "    # Calculate daily price change: 1 if price is up, -1 if down, 0 if unchanged\n",
        "    price_change = df['Close'].diff()\n",
        "\n",
        "    # Use price change to decide whether to add or subtract volume\n",
        "    obv = (price_change > 0).astype(int) * df['Volume']  # Volume when price goes up\n",
        "    obv -= (price_change < 0).astype(int) * df['Volume']  # Volume when price goes down\n",
        "\n",
        "    # We accumulate the OBV by taking the cumulative sum of the volume changes\n",
        "    obv = obv.cumsum()\n",
        "\n",
        "    return obv\n",
        "  except Exception as e:\n",
        "      print(\"Something went wrong while computing the OBV\", e)\n",
        "\n",
        "def is_bullish_engulfing(df):\n",
        "    prev = df.iloc[-2]\n",
        "    curr = df.iloc[-1]\n",
        "    return (\n",
        "        prev['Close'].iloc[0] < prev['Open'].iloc[0] and # Previous red\n",
        "        curr['Close'].iloc[0] > curr['Open'].iloc[0] and # Current green\n",
        "        curr['Close'].iloc[0] > prev['Open'].iloc[0] and\n",
        "        curr['Open'].iloc[0] < prev['Close'].iloc[0]\n",
        "    )\n",
        "\n",
        "# Function to calculate risk-reward ratio\n",
        "def calculate_risk_reward(df):\n",
        "  try:\n",
        "    if df.empty or len(df) < 20:  # Ensure there are enough data points\n",
        "        return np.nan\n",
        "\n",
        "    #latest_price = df['Close'].iloc[-1].iloc[0]\n",
        "    latest_price = df['Close'].iloc[-1]\n",
        "\n",
        "    # Use the ATR for setting support level\n",
        "    atr = df['ATR'].iloc[-1]  # Latest ATR value\n",
        "    price_ema = df['8_day_EMA'].iloc[-1]\n",
        "    atr_multiple = 2.25  # You can adjust this multiplier based on your strategy\n",
        "\n",
        "    # Calculate the support level using the ATR\n",
        "    trailing = atr\n",
        "    support_level = price_ema - (trailing * atr_multiple)\n",
        "    resistance_level = price_ema + (trailing * atr_multiple)\n",
        "\n",
        "    return support_level, latest_price, trailing,resistance_level\n",
        "  except Exception as e:\n",
        "      print(\"Something went wrong while computing the reward-risk ratio\", e)\n",
        "\n",
        "# Function to fetch daily data\n",
        "def get_daily_data(ticker):\n",
        "    df = yf.download(ticker, period=\"1y\", interval=\"1d\",auto_adjust=True)\n",
        "    if isinstance(df.columns, pd.MultiIndex):\n",
        "        df.columns = df.columns.get_level_values(0)  # keep only first level\n",
        "    df['20_day_SMA'] = df['Close'].rolling(window=20).mean()\n",
        "    df['20_day_EMA'] = df['Close'].ewm(span=20, adjust=False).mean()\n",
        "    df['50_day_avg_volume'] = df['Volume'].rolling(window=50).mean()\n",
        "    df['8_day_EMA'] = df['Close'].ewm(span=8, adjust=False).mean()\n",
        "    df['15_day_EMA'] = df['Close'].ewm(span=15, adjust=False).mean()\n",
        "    df['21_day_EMA'] = df['Close'].ewm(span=21, adjust=False).mean()\n",
        "    df['26_day_EMA'] = df['Close'].ewm(span=26, adjust=False).mean()\n",
        "    df['5_day_SMA'] = df['Close'].rolling(window=5).mean()\n",
        "    df['50_day_SMA'] = df['Close'].rolling(window=50).mean()\n",
        "    df['100_day_SMA'] = df['Close'].rolling(window=100).mean()\n",
        "    df['200_day_SMA'] = df['Close'].rolling(window=200).mean()\n",
        "    # Slope for 5-day SMA (short-term trend)\n",
        "    df['slope5_raw'] = rolling_regression_slope(df['5_day_SMA'], window=10)\n",
        "    df['slope5_pct_per_day'] = df['slope5_raw'] / df['5_day_SMA']  # fractional change per day\n",
        "    df['slope5_annualized_pct'] = df['slope5_pct_per_day'] * 252 * 100  # % per year\n",
        "    # Slope for 50-day SMA (intermediate-term trend)\n",
        "    df['slope50_raw'] = rolling_regression_slope(df['50_day_SMA'], window=10)\n",
        "    df['slope50_pct_per_day'] = df['slope50_raw'] / df['50_day_SMA']  # fractional change per day\n",
        "    df['slope50_annualized_pct'] = df['slope50_pct_per_day'] * 252 * 100  # % per year\n",
        "    df['ATR'] = compute_atr(df, 10)\n",
        "    df[\"8EMA_plus_ATR\"] = df[\"8_day_EMA\"] + 0.5* df[\"ATR\"]\n",
        "    df[\"8EMA_plus_ATRL\"] = df[\"8_day_EMA\"] + 1* df[\"ATR\"]\n",
        "    # Compute MACD using ta\n",
        "    df[\"MACD_Line\"] = ta.trend.macd(df[\"Close\"], window_slow=26, window_fast=12)\n",
        "    df[\"Signal_Line\"] = ta.trend.macd_signal(df[\"Close\"], window_slow=26, window_fast=12, window_sign=9)\n",
        "    df[\"MACD_Hist\"] = ta.trend.macd_diff(df[\"Close\"], window_slow=26, window_fast=12, window_sign=9)\n",
        "    df[\"MACD_Hist_above_zero\"] = df[\"MACD_Hist\"] > 0\n",
        "    df[\"MACD_Hist_below_zero\"] = df[\"MACD_Hist\"] < 0\n",
        "    df['macd_above_signal'] = df['MACD_Line'] > df['Signal_Line']\n",
        "    df['macd_below_signal'] = df['MACD_Line'] < df['Signal_Line']\n",
        "    df['VWAP'] = calculate_vwap(df)\n",
        "    # Compute raw EFI\n",
        "    df['EFI'] = (df['Close'].diff()) * df['Volume']\n",
        "    # Compute EMA of EFI\n",
        "    df['EFI_EMA'] = df['EFI'].ewm(span=13, adjust=False).mean()\n",
        "    # Determine if EFI_EMA is rising or falling\n",
        "    df['EFI_EMA_Trend'] = df['EFI_EMA'].diff().apply(lambda x: 'Rising' if x > 0 else 'Falling')\n",
        "    # Calculate ADX, +DMI and -DMI\n",
        "    high = df['High']\n",
        "    low = df['Low']\n",
        "    close = df['Close']\n",
        "    # Calculate directional movements\n",
        "    up_move = high.diff()\n",
        "    down_move = -low.diff()\n",
        "    plus_dm = np.where((up_move > down_move) & (up_move > 0), up_move, 0.0)\n",
        "    minus_dm = np.where((down_move > up_move) & (down_move > 0), down_move, 0.0)\n",
        "    # Calculate True Range (TR)\n",
        "    tr1 = high - low\n",
        "    tr2 = (high - close.shift()).abs()\n",
        "    tr3 = (low - close.shift()).abs()\n",
        "    tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)\n",
        "    # Smooth TR, +DM, and -DM using Wilder’s smoothing\n",
        "    atr = tr.rolling(window=14).sum()\n",
        "    plus_dm_series = pd.Series(plus_dm.ravel(), index=df.index).astype(float)\n",
        "    minus_dm_series = pd.Series(minus_dm.ravel(), index=df.index).astype(float)\n",
        "    plus_dm_smoothed = plus_dm_series.rolling(window=14).sum()\n",
        "    minus_dm_smoothed = minus_dm_series.rolling(window=14).sum()\n",
        "    # Directional Indicators\n",
        "    plus_di = 100 * (plus_dm_smoothed / atr)\n",
        "    minus_di = 100 * (minus_dm_smoothed / atr)\n",
        "    # DX and ADX\n",
        "    dx = 100 * (np.abs(plus_di - minus_di) / (plus_di + minus_di))\n",
        "    adx = dx.rolling(window=14).mean()\n",
        "    # Add results to original DataFrame\n",
        "    df['+DI'] = plus_di\n",
        "    df['-DI'] = minus_di\n",
        "    df['ADX'] = adx\n",
        "    df['di_flag'] = df['+DI'] > df['-DI']\n",
        "    df['di_flag'] = df['di_flag'].astype(int)\n",
        "    df['adx_indicator'] = np.where(df['ADX'] > 14, 1, 0)\n",
        "    df['adx_signal'] = df['adx_indicator'] * df['di_flag']\n",
        "\n",
        "    return df\n",
        "\n",
        "# Function to fetch hourly data\n",
        "def get_30min_data(ticker):\n",
        "    df = yf.download(ticker, interval='30m', period='60d',auto_adjust=True)\n",
        "    if isinstance(df.columns, pd.MultiIndex):\n",
        "      df.columns = df.columns.get_level_values(0)  # keep only first level\n",
        "\n",
        "    df['65d_SMA'] = df['Close'].rolling(window=65).mean()\n",
        "    # Slope calculation: regression over recent 10 bars (~5 trading hours)\n",
        "    df['slope_raw'] = rolling_regression_slope(df['65d_SMA'], window=10)\n",
        "    # Normalize → fractional change per 30-minute bar\n",
        "    df['slope_norm'] = df['slope_raw'] / df['65d_SMA']\n",
        "    # Annualize to % per year (standard for 30m regular hours)\n",
        "    bars_per_year = 252 * 13\n",
        "    df['SMA_Slope'] = df['slope_norm'] * bars_per_year * 100\n",
        "    # Short-term & medium-term moving averages\n",
        "    df['21_EMA'] = df['Close'].ewm(span=21, adjust=False).mean()\n",
        "    df['50_EMA'] = df['Close'].ewm(span=50, adjust=False).mean()\n",
        "    df['200_EMA'] = df['Close'].ewm(span=200, adjust=False).mean()\n",
        "    # Calculate MACD and Signal Line\n",
        "    df['12_EMA'] = df['Close'].ewm(span=12, adjust=False).mean()\n",
        "    df['26_EMA'] = df['Close'].ewm(span=26, adjust=False).mean()\n",
        "    # Compute MACD Line\n",
        "    df['MACD_Line'] = df['12_EMA'] - df['26_EMA']\n",
        "    # Compute Signal Line (9-day EMA of MACD Line)\n",
        "    df['Signal_Line'] = df['MACD_Line'].ewm(span=9, adjust=False).mean()\n",
        "    df['MACD_Hist'] = df['MACD_Line'] - df['Signal_Line']\n",
        "    return df\n",
        "\n",
        "\n",
        "# Function to fetch hourly data\n",
        "def get_15min_data(ticker):\n",
        "    df = yf.download(ticker, interval='15m', period='30d',auto_adjust=True)\n",
        "    if isinstance(df.columns, pd.MultiIndex):\n",
        "      df.columns = df.columns.get_level_values(0)  # keep only first level\n",
        "\n",
        "    df['130d_SMA'] = df['Close'].rolling(window=130).mean()\n",
        "    # Slope calculation: regression over recent 10 bars (~5 trading hours)\n",
        "    df['slope_raw'] = rolling_regression_slope(df['130d_SMA'], window=10)\n",
        "    # Normalize → fractional change per 15-minute bar\n",
        "    df['slope_norm'] = df['slope_raw'] / df['130d_SMA']\n",
        "    # Annualize to % per year (standard for 30m regular hours)\n",
        "    bars_per_year = 252 * 26\n",
        "    df['SMA_Slope'] = df['slope_norm'] * bars_per_year * 100\n",
        "    # Short-term & medium-term moving averages\n",
        "    df['21_EMA'] = df['Close'].ewm(span=21, adjust=False).mean()\n",
        "    df['50_EMA'] = df['Close'].ewm(span=50, adjust=False).mean()\n",
        "    df['200_EMA'] = df['Close'].ewm(span=200, adjust=False).mean()\n",
        "    return df\n",
        "\n",
        "\n",
        "# Function to check monthly trend\n",
        "def is_monthly_trend_bullish(df):\n",
        "    if df.empty:\n",
        "        return False\n",
        "\n",
        "\n",
        "    adx_ok              = df['adx_signal'].iloc[-1] == 1\n",
        "    latest_price        = df['Close'].iloc[-1].iloc[0]\n",
        "    latest_sma          = df['10_month_SMA'].iloc[-1]\n",
        "    macd_bullish_signal = is_macd_bullish(df)\n",
        "    above_10_month_SMA  = (latest_price > latest_sma)\n",
        "\n",
        "    return above_10_month_SMA and macd_bullish_signal and adx_ok\n",
        "\n",
        "\n",
        "# Function to check weekly trend\n",
        "def is_weekly_trend_bullish(df):\n",
        "    if df.empty:\n",
        "        return False\n",
        "\n",
        "    latest_price = df['Close'].iloc[-1].iloc[0]\n",
        "    latest_30sma = df['30_week_SMA'].iloc[-1]\n",
        "    latest_10sma = df['10_week_SMA'].iloc[-1]\n",
        "    sma_10_above_30 = latest_10sma > latest_30sma\n",
        "    above_10_week_SMA = latest_price > latest_10sma\n",
        "    above_30_week_SMA = latest_price > latest_30sma\n",
        "    sma_slope = df['SMA_Slope'].iloc[-1]> 30\n",
        "    obv_slope = df['OBV_Slope'].iloc[-1]> 0\n",
        "    macd_bullish_signal =  is_macd_bullish(df)\n",
        "    elderforce_trend_ok = df['EFI_EMA_Trend'].iloc[-1] == 'Rising'\n",
        "    adx_ok = df['adx_signal'].iloc[-1] == 1\n",
        "    elderforce_ema_ok = df['EFI_EMA'].iloc[-1] > 0\n",
        "    volume_ok = df['Volume'].iloc[-1] > df['30_week_avg_volume'].iloc[-1] # Institutional interest\n",
        "    volume_ok = volume_ok.iloc[0]\n",
        "    # Calculate the OBV Moving Average\n",
        "    df['OBV_EMA'] = df['OBV'].ewm(span=10, adjust=False).mean()\n",
        "    # OBV trending up if current OBV is above the 30-period EMA\n",
        "    obv_trending_up = df['OBV'].iloc[-1] > df['OBV_EMA'].iloc[-1]\n",
        "    # OBV trending down if current OBV is below the 30-period EMA\n",
        "    obv_trending_down = df['OBV'].iloc[-1] < df['OBV_EMA'].iloc[-1]\n",
        "    trend_ok = sma_10_above_30  and above_10_week_SMA and above_30_week_SMA and adx_ok\n",
        "    no_overhead_supply = df['No_Overhead_Resistance'].iloc[-1]\n",
        "    above_52w_high = df['above_52w_high'].iloc[-1]\n",
        "    time.sleep(2)  # Add a delay of 1 second between requests\n",
        "\n",
        "    return  trend_ok and sma_slope # and macd_bullish_signal\n",
        "\n",
        "\n",
        "\n",
        "# Function to check daily entry signal\n",
        "def is_daily_entry_signal(df2):\n",
        "    if df2.empty:\n",
        "        return False\n",
        "\n",
        "    df = df2.copy()\n",
        "    latest_price = df['Close'].iloc[-1]\n",
        "    sma_slope_5  = df['slope5_annualized_pct'].iloc[-1] > 50\n",
        "    sma_slope_50 = df['slope50_annualized_pct'].iloc[-1] > 50\n",
        "    latest_8ema = df['8_day_EMA'].iloc[-1]\n",
        "    latest_5sma = df['5_day_SMA'].iloc[-1]\n",
        "    latest_15ema = df['15_day_EMA'].iloc[-1]\n",
        "    latest_20sma = df['20_day_SMA'].iloc[-1]\n",
        "    latest_50sma = df['50_day_SMA'].iloc[-1]\n",
        "    latest_100sma = df['100_day_SMA'].iloc[-1]\n",
        "    latest_200sma = df['200_day_SMA'].iloc[-1]\n",
        "    above_20sma = latest_price > latest_20sma\n",
        "    above_50sma = latest_price > latest_50sma\n",
        "    above_100sma = latest_price > latest_100sma\n",
        "    above_200sma = latest_price > latest_200sma\n",
        "    above_8ema = latest_price >= latest_5sma\n",
        "    is_8ema_above_15ema = latest_8ema > latest_15ema\n",
        "    is_20sma_above_50sma = latest_20sma > latest_50sma\n",
        "    is_50sma_above_100sma = latest_50sma > latest_100sma\n",
        "    is_50sma_above_200sma = latest_50sma > latest_200sma\n",
        "    is_100sma_above_200sma = latest_100sma > latest_200sma\n",
        "    volume_ok = df['Volume'].iloc[-1] >= 1.1* df['50_day_avg_volume'].iloc[-1] # Institutional interest\n",
        "    volume_ok = volume_ok\n",
        "    macd_bullish_signal = df[\"MACD_Hist_above_zero\"].iloc[-1] #is_macd_bullish(df)\n",
        "    #vwap_price = df['VWAP'].iloc[-1]\n",
        "    elderforce_trend_ok = df['EFI_EMA_Trend'].iloc[-1] == 'Rising'\n",
        "    elderforce_ema_ok = df['EFI_EMA'].iloc[-1] > 0\n",
        "    adx_ok = df['adx_signal'].iloc[-1] == 1\n",
        "    slopes_ok =  sma_slope_5 and sma_slope_50\n",
        "    moving_averages_ok = above_50sma and above_100sma and above_200sma \\\n",
        "                          and is_50sma_above_100sma \\\n",
        "                          and is_50sma_above_200sma and is_100sma_above_200sma \\\n",
        "\n",
        "    # Look for a breakout above 20-day SMA & RSI > 50\n",
        "    return moving_averages_ok and slopes_ok and adx_ok\n",
        "\n",
        "\n",
        "def get_heikin_ashi_signal(ticker=\"AAPL\", period=\"6mo\", interval=\"1d\"):\n",
        "    # Fetch OHLC data\n",
        "    df = yf.download(ticker, period=period, interval=interval, auto_adjust=True)\n",
        "    if isinstance(df.columns, pd.MultiIndex):\n",
        "        df.columns = df.columns.get_level_values(0)  # keep only first level\n",
        "\n",
        "    # Compute Heikin Ashi candles\n",
        "    ha_df = pd.DataFrame(index=df.index)\n",
        "    ha_df['HA_Close'] = (df['Open'] + df['High'] + df['Low'] + df['Close']) / 4\n",
        "\n",
        "    ha_open = []\n",
        "    for i in range(len(df)):\n",
        "        if i == 0:\n",
        "             ha_open.append((df['Open'].iloc[i] + df['Close'].iloc[i]) / 2)\n",
        "        else:\n",
        "            ha_open.append((ha_open[i-1] + ha_df['HA_Close'].iloc[i-1]) / 2)\n",
        "    ha_df['HA_Open'] = ha_open\n",
        "    ha_df['HA_High'] = ha_df[['HA_Open', 'HA_Close']].assign(High=df['High']).max(axis=1)\n",
        "    ha_df['HA_Low'] = ha_df[['HA_Open', 'HA_Close']].assign(Low=df['Low']).min(axis=1)\n",
        "\n",
        "    # Combine with original\n",
        "    df = df.join(ha_df)\n",
        "    # Check for green candle with flat bottom\n",
        "    last = df.iloc[-1]\n",
        "    green_candle = last['HA_Close'] > last['HA_Open']\n",
        "    flat_bottom = abs(last['HA_Open'] - last['HA_Low']) < 0.01  # tiny wick or flat bottom tolerance\n",
        "    signal = green_candle and flat_bottom\n",
        "\n",
        "    print(f\"\\n🔍 Checking {ticker} ({interval} timeframe)\")\n",
        "    print(f\"HA_Open: {last['HA_Open']:.2f}, HA_Close: {last['HA_Close']:.2f}, HA_Low: {last['HA_Low']:.2f}\")\n",
        "    if signal:\n",
        "        print(\"✅ Heikin Ashi candle is GREEN with a FLAT bottom — strong bullish signal!\")\n",
        "    elif green_candle:\n",
        "        print(\"🟢 Candle is green but not flat-bottomed — still bullish, but less strong.\")\n",
        "    else:\n",
        "        print(\"🔴 Not a bullish candle — no entry confirmation yet.\")\n",
        "\n",
        "    return signal, green_candle\n",
        "\n",
        "# Check entry conditions\n",
        "def check_entry_conditions(tickers):\n",
        "    results = []\n",
        "    for ticker in tickers:\n",
        "      df = get_daily_data(ticker)\n",
        "      latest_price = df['Close'].iloc[-1]\n",
        "      prev_price = df['Close'].iloc[-2]\n",
        "      latest_sma = df['50_day_SMA'].iloc[-1]\n",
        "      latest_price_8ema =df['8_day_EMA'].iloc[-1]\n",
        "      latest_price_21ema =df['21_day_EMA'].iloc[-1]\n",
        "      price_threshold_ATR = df['8EMA_plus_ATR'].iloc[-1]\n",
        "      price_threshold_ATRL = df['8EMA_plus_ATRL'].iloc[-1]\n",
        "      macd_bullish_signal = df['macd_above_signal'].iloc[-1]\n",
        "      mfi_signal = money_flow_signals(df)\n",
        "      # Print results\n",
        "      print(f\"\\nMoney flow indicator for {ticker} is:\")\n",
        "      print(mfi_signal)\n",
        "      macdv_signal = macdv(df['Close'])\n",
        "      print(f\"\\nMacd-V indicator for {ticker} is:\")\n",
        "      print(macdv_signal )\n",
        "\n",
        "\n",
        "      df_entry              = get_30min_data(ticker)\n",
        "      latest_priceh_5sma    = df_entry['65d_SMA'].iloc[-1]\n",
        "      latest_priceh         = df_entry['Close'].iloc[-1]\n",
        "      sma_slope_h           = df_entry['SMA_Slope'].iloc[-1]> 30\n",
        "      HA_buy_signal_h,gc_h  = get_heikin_ashi_signal(ticker, period=\"90d\", interval=\"1d\")\n",
        "\n",
        "      df_refined_entry      = get_15min_data(ticker)\n",
        "      latest_pricem_5sma    = df_refined_entry['130d_SMA'].iloc[-1]\n",
        "      latest_pricem         = df_refined_entry['Close'].iloc[-1]\n",
        "      sma_slope_m           = df_refined_entry['SMA_Slope'].iloc[-1]> 30\n",
        "\n",
        "\n",
        "      refined_entry_signal =  sma_slope_h or sma_slope_m\n",
        "\n",
        "\n",
        "      if latest_price > price_threshold_ATRL:\n",
        "        entry_signal = \"Extended Momentum Entry\"\n",
        "      elif latest_price >= latest_price_8ema and (latest_price <= price_threshold_ATR) :\n",
        "        entry_signal = \"Aline Entry\"\n",
        "      elif (latest_price > price_threshold_ATR) and (latest_price <= price_threshold_ATRL) and refined_entry_signal  :\n",
        "        entry_signal = \"True Trend Entry\"\n",
        "      elif (latest_price < latest_price_8ema) and (latest_price >= latest_price_21ema) :\n",
        "          entry_signal= \"Bline Entry\"\n",
        "      elif  (latest_price <= latest_price_21ema) and (latest_price >= latest_sma) :\n",
        "          entry_signal = \"Below Bline Entry\"\n",
        "      elif  latest_price < latest_sma:\n",
        "          entry_signal = \"Bearish\"\n",
        "\n",
        "      else:\n",
        "        entry_signal = \"Other\"\n",
        "      results.append([ticker, entry_signal])\n",
        "    # Convert results to DataFrame\n",
        "    df_results = pd.DataFrame(results, columns=[\"Asset\", \"Entry_Signal\"])\n",
        "    return df_results\n",
        "\n",
        "# Multi-timeframe strategy check returning a DataFrame\n",
        "def check_mtf_entry(tickers):\n",
        "    results = []\n",
        "\n",
        "    for ticker in tickers:\n",
        "        monthly_df = get_monthly_data(ticker)\n",
        "        weekly_df = get_weekly_data(ticker)\n",
        "        daily_df = get_daily_data(ticker)\n",
        "\n",
        "        if is_weekly_trend_bullish(weekly_df) and is_monthly_trend_bullish(monthly_df):\n",
        "            if is_daily_entry_signal(daily_df):\n",
        "                entry_signal = \"Entry Confirmed ✅\"\n",
        "                results.append([ticker, entry_signal])\n",
        "            else:\n",
        "                entry_signal = \"No Entry Yet on Daily Timeframe ⏳\"\n",
        "                #results.append([ticker, entry_signal])\n",
        "        else:\n",
        "            entry_signal = \"Monthly or Weekly Trend Not Bullish ❌\"\n",
        "            #results.append([ticker, entry_signal])\n",
        "\n",
        "        #results.append([ticker, entry_signal])\n",
        "        time.sleep(2)  # Add a delay of 1 second between requests\n",
        "\n",
        "    # Convert results to DataFrame\n",
        "    df_results = pd.DataFrame(results, columns=[\"Asset\", \"Entry_Signal\"])\n",
        "    return df_results\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lppiGKsqeGzm"
      },
      "outputs": [],
      "source": [
        "# Multi-time frame entry Check\n",
        "#df_results = pd.DataFrame(results).dropna()\n",
        "etfs_to_check = df_o['Asset'].tolist()\n",
        "# for quick testing\n",
        "#etfs_to_check  =['EZA', 'GM', 'MU', 'LRCX', 'NVDA', 'CAT', 'WDC','ILF']\n",
        "df_signals = check_mtf_entry(etfs_to_check)\n",
        "\n",
        "df_signals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7huoxuBlbOJ"
      },
      "source": [
        "## Generate buy list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ZkXo-EzIHyZ"
      },
      "outputs": [],
      "source": [
        "df_final = df_signals[df_signals['Entry_Signal'] ==\"Entry Confirmed ✅\"]\n",
        "final_etfs_to_check = df_final['Asset'].tolist()\n",
        "\n",
        "#final_etfs_to_check.remove('REMX')\n",
        "buy_list = check_entry_conditions(final_etfs_to_check)\n",
        "\n",
        "buy_list\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kK4wljaehytU"
      },
      "source": [
        "# Find and filter correlated assets to reduce concentration risk."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3bR7La6-i1ra"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_uncorrelated_picks(tickers, ranked_picks, threshold=0.66, period=\"3mo\", interval=\"1d\"):\n",
        "    \"\"\"\n",
        "    Filters a ranked list of tickers to return only uncorrelated picks.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    tickers : list\n",
        "        All candidate tickers.\n",
        "    ranked_picks : list\n",
        "        Ranked list of tickers (best to worst).\n",
        "    threshold : float\n",
        "        Correlation threshold (default 0.66).\n",
        "    period : str\n",
        "        Data period for yfinance (default \"3mo\").\n",
        "    interval : str\n",
        "        Data interval (default \"1d\").\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    final_selection : list\n",
        "        List of uncorrelated tickers.\n",
        "    corr_matrix : DataFrame\n",
        "        Correlation matrix of daily returns.\n",
        "    \"\"\"\n",
        "    # Step 1: Get prices\n",
        "    data = yf.download(tickers, period=period, interval=interval,auto_adjust=True)[\"Close\"]\n",
        "    data = data.ffill()\n",
        "\n",
        "    # Step 2: Convert to daily returns\n",
        "    returns = data.pct_change().dropna()\n",
        "\n",
        "    # Step 3: Correlation matrix\n",
        "    corr_matrix = returns.corr()\n",
        "\n",
        "    # Step 4: Filter uncorrelated picks\n",
        "    final_selection = []\n",
        "    for pick in ranked_picks:\n",
        "        if all(abs(corr_matrix.loc[pick, sel]) <= threshold for sel in final_selection):\n",
        "            final_selection.append(pick)\n",
        "\n",
        "    return final_selection, corr_matrix\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uBBD38QcWImG"
      },
      "outputs": [],
      "source": [
        "# Apply TA filters and prioritize ETFs\n",
        "results = []\n",
        "buy_list = buy_list[buy_list['Entry_Signal'].isin([\n",
        "    'Aline Entry',\n",
        "    'True Trend Entry' ,\n",
        "    'Extended Momentum Entry'\n",
        "])]\n",
        "\n",
        "\n",
        "for etf in buy_list['Asset'].to_list():\n",
        "   df          = get_daily_data(etf)\n",
        "   price       = df['Close'].iloc[-1]\n",
        "   above_21EMA = price > df['21_day_EMA'].iloc[-1]\n",
        "   above_50sma = price  > df['50_day_SMA'].iloc[-1]\n",
        "\n",
        "   sma_slope_50 = df['slope50_annualized_pct'].iloc[-1]> 0\n",
        "   vwap_df     = anchored_vwap(etf, lookback_weeks=2)\n",
        "   vwap_sy     = anchored_vwap_old(etf, start_of_year)\n",
        "   ytd_vwap    = vwap_sy['anchored_vwap'].iloc[-1]\n",
        "   # MTD\n",
        "   vwap_mtd     = anchored_vwap_old(etf, first_day_month)\n",
        "   mtd_vwap    = vwap_mtd['anchored_vwap'].iloc[-1]\n",
        "   above_mtd_vwap = price > mtd_vwap\n",
        "\n",
        "   # WTD\n",
        "   #vwap_wtd     = anchored_vwap_old(etf, first_day_week )\n",
        "   #wtd_vwap    = vwap_wtd['anchored_vwap'].iloc[-1]\n",
        "   print(\"Current price is :\", price)\n",
        "   print(\"Year to date VWAP is :\", ytd_vwap)\n",
        "   vwap        = vwap_df['Anchored_VWAP'].iloc[-1]\n",
        "   vwap_signal = vwap_df['Signal'].iloc[-1]\n",
        "\n",
        "   swing_high =  vwap_df['Swing_High_Price'].iloc[-1]\n",
        "   above_vwap  = price > vwap\n",
        "   above_ytd_vwap = price > ytd_vwap\n",
        "\n",
        "\n",
        "   if  sma_slope_50 and above_mtd_vwap and vwap_signal :\n",
        "    support_level, latest_price, trail,resistance = calculate_risk_reward(df)\n",
        "    entry_price = latest_price + min(0.25, 0.1*trail)\n",
        "    trail = 1* trail\n",
        "    risk = np.abs(entry_price- support_level)\n",
        "    take_profit_1=  entry_price+ (1 *risk)\n",
        "    resistance_level = entry_price + (1.1 *risk)\n",
        "    reward = resistance_level - entry_price\n",
        "    risk_reward_ratio = reward / risk\n",
        "    # Ensure risk is greater than zero before division\n",
        "    if risk > 0:\n",
        "        rr_ratio_1  = np.abs(take_profit_1- entry_price) / risk\n",
        "        rr_ratio  = reward / risk\n",
        "    else:\n",
        "        rr_ratio = np.nan\n",
        "\n",
        "    take_profit1_perc = ((take_profit_1- entry_price )/entry_price )*100\n",
        "    stop_loss_perc = ((support_level- entry_price)/entry_price )*100\n",
        "    take_profit_perc = ((resistance_level- entry_price )/entry_price )*100\n",
        "    # Fetch the Entry_Signal from buy_list\n",
        "    entry_signal = buy_list.loc[buy_list['Asset'] == etf, 'Entry_Signal'].values[0]\n",
        "\n",
        "    # Append results with Entry_Signal\n",
        "    results.append({\n",
        "            \"Asset\": etf,\n",
        "            #\"Swing High\": swing_high,\n",
        "            \"Risk-Reward\": rr_ratio,\n",
        "            \"Stop Out Price\": support_level,\n",
        "            #\"Take Profit1\": take_profit_1,\n",
        "            \"Target Price\": resistance_level,\n",
        "            \"Current Price\": latest_price,\n",
        "            \"Entry Price\": entry_price,\n",
        "            \"Trail Price\": trail,\n",
        "            \"Entry Signal\": entry_signal,  # Add entry signal\n",
        "            \"stop_loss_perc\": stop_loss_perc,\n",
        "            #\"take_profit1_perc\": take_profit1_perc,\n",
        "            \"take_profit_perc\": take_profit_perc,\n",
        "            \"Anchored VWAP\": vwap,\n",
        "            \"MTD VWAP\": mtd_vwap\n",
        "            #\"WTD VWAP\": wtd_vwap,\n",
        "            #\"YTD VWAP\": ytd_vwap\n",
        "        })\n",
        "\n",
        "    time.sleep(2)  # Add a delay of 1 second between requests\n",
        "\n",
        "\n",
        "# Sort ETFs by highest risk-to-reward ratio\n",
        "try:\n",
        "   df_results = pd.DataFrame(results).dropna().sort_values(by=\"Risk-Reward\", ascending=False).reset_index(drop = True)\n",
        "except Exception as e:\n",
        "  print(\"No Asset to buy today, check back some other time!\")\n",
        "  df_results = pd.DataFrame({\"Asset\": [\"No Asset available\"]})\n",
        "\n",
        "df2 = df_results.merge(df_o[['Asset','Type', 'score']], on='Asset', how='left')\n",
        "df2['timestamp'] = datetime.now()\n",
        "df2 = df2.sort_values(by='score', ascending=False)\n",
        "df2.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUkA7I2kSv2c"
      },
      "source": [
        "## Sentiment Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rtj7SdqASu6Z"
      },
      "outputs": [],
      "source": [
        "NEWS_API_KEY = \"15c99612003d4971ad86698b50ed0bd7\"  # Get one free from https://newsapi.org/\n",
        "LOOKBACK_DAYS = 3\n",
        "\n",
        "# Fetch recent news\n",
        "def fetch_news(ticker, lookback_days=3):\n",
        "    url = f\"https://newsapi.org/v2/everything?q={ticker}&language=en&from={(datetime.now() - timedelta(days=lookback_days)).date()}&apiKey={NEWS_API_KEY}\"\n",
        "    resp = requests.get(url).json()\n",
        "    if \"articles\" not in resp:\n",
        "        return []\n",
        "    return [a[\"title\"] for a in resp[\"articles\"]]\n",
        "\n",
        "# Finbert Sentiment Scoring\n",
        "finbert = pipeline(\"sentiment-analysis\", model=\"ProsusAI/finbert\")\n",
        "\n",
        "def get_sentiment_scores(news_list):\n",
        "    if not news_list:\n",
        "        return 0\n",
        "    results = finbert(news_list)\n",
        "    time.sleep(2)  # Add a delay of 1 second between requests\n",
        "    scores = [1 if r[\"label\"] == \"positive\" else -1 if r[\"label\"] == \"negative\" else 0 for r in results]\n",
        "    return np.mean(scores)\n",
        "\n",
        "def build_sentiment_table(TICKERS):\n",
        "    records = []\n",
        "    for ticker in TICKERS:\n",
        "        print(f\"Processing {ticker}...\")\n",
        "        news = fetch_news(ticker, LOOKBACK_DAYS)\n",
        "        sentiment_score = get_sentiment_scores(news)\n",
        "        combined = {\n",
        "            \"Ticker\": ticker,\n",
        "            \"Sentiment\": sentiment_score\n",
        "        }\n",
        "        records.append(combined)\n",
        "    df = pd.DataFrame(records)\n",
        "\n",
        "    # Weighted score (adjustable)\n",
        "    df[\"Composite_Score\"] = (\n",
        "\n",
        "        df[\"Sentiment\"].rank(pct=True)\n",
        "    )\n",
        "\n",
        "    df = df.sort_values(\"Composite_Score\", ascending=False).reset_index(drop=True)\n",
        "    return df\n",
        "\n",
        "# Run sentiment scoring\n",
        "tickers = df2['Asset'].tolist()\n",
        "results = build_sentiment_table(tickers)\n",
        "top_assets = results[results[\"Sentiment\"] >= 0]\n",
        "\n",
        "top_assets.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HR3kZNtOVonH"
      },
      "source": [
        "# US Stock Entries (Day Trade)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K2TMbSSCVo6L"
      },
      "outputs": [],
      "source": [
        "# SP 500 stocks\n",
        "# Fetch the Entry_Signal from buy_list\n",
        "try:\n",
        "  df3 = df2[df2['Asset'].isin(top_assets['Ticker'])]\n",
        "  sp500_stocks_dt = df3[(df3['Type'] == 'Stock') & (df3['Entry Signal'] == 'Extended Momentum Entry')].reset_index(drop=True)\n",
        "except Exception as e:\n",
        "  print(\"No Asset to buy today, check back some other time!\")\n",
        "  sp500_stocks_dt = pd.DataFrame({\"Asset\": [\"No Asset available\"]})\n",
        "\n",
        "sp500_stocks_dt\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJxoFGjwe8Ja"
      },
      "source": [
        "# US Stock Entries (Aline Entry)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FAftLZAve7NG"
      },
      "outputs": [],
      "source": [
        "# Fetch the Entry_Signal from buy_list\n",
        "# Filter US stocks for Aline Entry\n",
        "try:\n",
        "  us_stocks = df3[(df3['Type'] == 'Stock') & (df3['Entry Signal'].isin(['Aline Entry']))].reset_index(drop=True)\n",
        "\n",
        "  tickers = us_stocks['Asset'].tolist()  # Replace with your list of tickers\n",
        "  ranked_picks = tickers\n",
        "\n",
        "  final_stock_selection, corr_matrix = get_uncorrelated_picks(tickers, ranked_picks, threshold=0.66)\n",
        "\n",
        "  #print(\"Final uncorrelated picks:\", final_selection)\n",
        "  print(\"\\nCorrelation matrix:\\n\", corr_matrix)\n",
        "\n",
        "  # Keep only rows where Asset is in filtered\n",
        "  filtered_stock_list = us_stocks [us_stocks [\"Asset\"].isin(final_stock_selection)]\n",
        "except Exception as e:\n",
        "  print(\"No Asset to buy today, check back some other time!\")\n",
        "  filtered_stock_list = pd.DataFrame({\"Asset\": [\"No Asset available\"]})\n",
        "\n",
        "filtered_stock_list"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# US Stock Entries (True Trend Entry)"
      ],
      "metadata": {
        "id": "OOqV38IrtAOn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch the Entry_Signal from buy_list\n",
        "# Filter US stocks for Aline Entry\n",
        "try:\n",
        "  us_stocks = df3[(df3['Type'] == 'Stock') & (df3['Entry Signal'].isin(['True Trend Entry']))].reset_index(drop=True)\n",
        "\n",
        "  tickers = us_stocks['Asset'].tolist()  # Replace with your list of tickers\n",
        "  ranked_picks = tickers\n",
        "\n",
        "  final_stock_selection, corr_matrix = get_uncorrelated_picks(tickers, ranked_picks, threshold=0.66)\n",
        "\n",
        "  #print(\"Final uncorrelated picks:\", final_selection)\n",
        "  print(\"\\nCorrelation matrix:\\n\", corr_matrix)\n",
        "\n",
        "  # Keep only rows where Asset is in filtered\n",
        "  filtered_stock_list2 = us_stocks [us_stocks [\"Asset\"].isin(final_stock_selection)]\n",
        "except Exception as e:\n",
        "  print(\"No Asset to buy today, check back some other time!\")\n",
        "  filtered_stock_list2 = pd.DataFrame({\"Asset\": [\"No Asset available\"]})\n",
        "\n",
        "filtered_stock_list2"
      ],
      "metadata": {
        "id": "CAm6kaGes-01"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}